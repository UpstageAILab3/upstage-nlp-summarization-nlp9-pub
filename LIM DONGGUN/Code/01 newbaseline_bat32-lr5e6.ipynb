{"cells":[{"cell_type":"markdown","metadata":{"id":"_UvLnUoquU67"},"source":["## 0. 준비"]},{"cell_type":"markdown","metadata":{"id":"JVXQOkJKuU68"},"source":["### 1) 라이브러리 설치"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7eVJxImiuU68","executionInfo":{"status":"ok","timestamp":1725960101793,"user_tz":-540,"elapsed":36775,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"2f9cf35c-a720-43c1-abb2-f5b68819125a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Downloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n","Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.9\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.4.0+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.5)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (71.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.8)\n","Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n","Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.11.7 pytorch_lightning-2.4.0 torchmetrics-1.4.1\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n"]}],"source":["!pip install wandb\n","!pip install torch\n","!pip install pytorch_lightning\n","!pip install rouge"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yNUePe30uU69","executionInfo":{"status":"ok","timestamp":1725960101793,"user_tz":-540,"elapsed":4,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":[" #!wandb --help"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xjpRJqc_uU69","executionInfo":{"status":"ok","timestamp":1725960101793,"user_tz":-540,"elapsed":3,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["#!wandb login #--relogin\n","# kkukky@naver.com  220215bca12e71dfd5815f1648ca8dbbb2c1bef8\n","#  17b70d1b235684f485db5bcc4b47788ca0e90fd2"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--hRF5IeuU69","executionInfo":{"status":"ok","timestamp":1725960124303,"user_tz":-540,"elapsed":22513,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"4e271a21-a405-4b90-8efe-fc16201f2467"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["\n","import pandas as pd             # 데이터 프레임을 다루기 위한 라이브러리입니다. 주로 데이터 처리 및 분석에 사용됩니다.\n","import os                       # 운영 체제와 상호작용하기 위한 모듈로, 파일 및 디렉터리 작업에 사용됩니다.\n","import re                       # 정규 표현식을 사용하여 문자열을 검색, 처리하는 데 사용됩니다.\n","import json                     # JSON 형식의 데이터를 처리하기 위한 라이브러리입니다.\n","import yaml                     # YAML 형식의 데이터를 처리하기 위한 라이브러리입니다.\n","from glob import glob           # 특정 패턴에 맞는 파일 경로들을 리스트로 반환하는 모듈입니다.\n","from tqdm import tqdm           # 반복문에 대한 진행 상황을 시각적으로 보여주는 라이브러리입니다.\n","from pprint import pprint       # 데이터를 좀 더 읽기 쉽게 출력하기 위한 라이브러리입니다.\n","import torch                    # PyTorch 라이브러리로, 딥러닝 모델을 구축하고 학습하기 위한 핵심 라이브러리입니다.\n","import pytorch_lightning as pl  # PyTorch의 고수준 API로, 모델 학습을 간소화하고 구조화된 방식으로 진행할 수 있습니다.\n","from rouge import Rouge         # 텍스트 요약 및 생성 모델의 성능을 평가하기 위해 사용하는 지표 중 하나입니다.\n","\n","from torch.utils.data import Dataset, DataLoader  # 데이터셋을 다루고, 이를 모델 학습에 사용할 수 있도록 배치(batch) 단위로 나누는 데 사용됩니다.\n","from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig  # 트랜스포머 모델을 위한 라이브러리로, 토크나이저와 모델을 불러오는 데 사용됩니다.\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer  # Seq2Seq (Sequence-to-Sequence) 모델 학습을 위한 도구와 설정을 제공합니다.\n","from transformers import Trainer, TrainingArguments  # 일반적인 모델 학습을 위한 도구와 설정을 제공합니다.\n","from transformers import EarlyStoppingCallback  # 학습 과정에서 성능 향상이 없을 때 조기 종료를 할 수 있도록 도와주는 콜백 함수입니다.\n","\n","import wandb                    # 모델 학습 과정을 쉽게 추적하고 시각화할 수 있는 툴입니다. 주로 실험 관리 및 결과 기록에 사용됩니다.\n","\n","wandb.login(key=\"220215bca12e71dfd5815f1648ca8dbbb2c1bef8\")\n","\n","#!wandb login #--relogin\n","# kkukky@naver.com     220215bca12e71dfd5815f1648ca8dbbb2c1bef8\n","# kkukky81@gmail.com   17b70d1b235684f485db5bcc4b47788ca0e90fd2\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_zdzJm6-uU6-"},"source":["### 2) 모델 선택, title 만들기"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298,"referenced_widgets":["dad34778350e46358944311abb26b4bc","7739a59001124e83ac2b38b6ea33ba11","2dba2726a7bd49c7a4bf200766e5baac","b37c223b354240a09306ab66fddd9fb1","5a5b335716824d3ba444e4bfd06070c9","e345f2e8c8cb4cfe8eb9f1ae7d2d4330","9604fbfe6c0e490fb671224fec6b3ca2","05554a3c1a704e45a965ca804c560da4","cd633cebc980491a89152679a9c7b002","8c1725c06a1c493d8d62f654743a2029","7ea9b168115349eb837b66fb89bc7b2e","470533f69d8f4b419ee7fc77ce43194c","bf36213116274c0da78089e1e4b8d556","6a14b1ee34134ba9992f5d10c8f3102f","f216aca8a26c4e1b9ee57b2cda2813f2","45d6b73bbaa440bf91b3094f205e4ac5","f5999d2518ba44aa9b63743af7b6f350","67908eee87564e7090a4b124620419c2","57dde2cfebbf444c88d522d8eedc1419","3da24c9e9f0a454c8239e932cbfb5df2","44953bbb5e744d1ab2d322e393eccf89","9bef013ac5f347aa88302f2b3da23320","77db6d046b424c8cb1c880804a7266a5","03a29e19e55a4709a482174fa5f2f3f4","822917dd324247c99cfc5ad0204f991a","f8828b027337456ca79440a26ee468eb","3805724fb39a4d4e906c4ffed8af26c2","6c153a5cd8be452d9f41eaced17c165f","4476b7cd6aff49f0a652f66de7ce3b4e","dc536aaa2d9a4bd8adef874bac22bcd8","6a97d407462342948ba03410897027dc","68b7a67166024621b3393cef5cb96193","eccb54365c3e4af0a35ac6e4ebc389bf"]},"id":"rLtG2OueuU6-","executionInfo":{"status":"ok","timestamp":1725960128895,"user_tz":-540,"elapsed":4595,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"8849f947-7b55-4559-8b02-6d9540c83d7e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad34778350e46358944311abb26b4bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470533f69d8f4b419ee7fc77ce43194c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77db6d046b424c8cb1c880804a7266a5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["###    jx7789_kobart_summary_v3-bat16-5l6-n4-b5    ###\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","### bart 계열\n","# model = \"digit82/kobart-summarization\"\n","# model = \"NLPBada/kobart-chat-persona-extraction-v2\"\n","# model = \"EbanLee/kobart-summary-v3\"\n","model = 'jx7789/kobart_summary_v3'\n","# model = \"ainize/kobart-news\" 아주 나쁨\n","# model = \"hyesunyun/update-summarization-bart-large-longformer\"\n","\n","### T5 계열\n","# model = \"t5-small\"\n","# model = \"KETI-AIR/ke-t5-base-ko\" 값이 안나옴\n","# model = \"eenzeenee/t5-base-korean-summarization\" 안됨\n","# model = 'psyche/KoT5-summarization' #안됨\n","# model = 'csebuetnlp/mT5_multilingual_XLSum'\n","\n","\n","train = \"train.csv\"\n","\n","para = \"-bat16-5l6-n4-b5\"\n","\n","title = model.replace('/','_') + para\n","\n","# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n","#tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")\n","tokenizer = AutoTokenizer.from_pretrained(model)\n","\n","#from transformers import AutoModel\n","\n","#model = AutoModel.from_pretrained(model, force_download=True)\n","\n","print('###   ', title, '   ###')\n","\n","#output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n"]},{"cell_type":"markdown","metadata":{"id":"1VY0zIejuU6-"},"source":["### 3) config 파일 만들기"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"1q0rrIB5uU6-","executionInfo":{"status":"ok","timestamp":1725960128895,"user_tz":-540,"elapsed":5,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["batch = 32\n","config_data = {\n","    \"general\": {\n","        \"data_path\": \"/content/drive/MyDrive/AILAB/NLP/data\",  # 모델 학습에 사용할 데이터가 저장된 경로를 지정합니다.\n","        #\"model_name\": \"digit82/kobart-summarization\",  # 사용할 사전 학습된 모델의 이름을 지정합니다.\n","        \"model_name\": model,  # 사용할 사전 학습된 모델의 이름을 지정합니다.\n","        \"output_dir\": \"./\"  # 모델의 출력물(예: 생성된 텍스트)을 저장할 디렉터리를 지정합니다.\n","    },\n","    \"training\": {\n","        \"overwrite_output_dir\": True,       # True로 설정하면, 기존에 존재하는 출력 디렉터리 내용을 덮어씁니다.\n","        \"num_train_epochs\": 20,             # 전체 데이터셋을 몇 번 반복해서 학습할지를 설정합니다. (20번)\n","        \"learning_rate\": 5e-6,              # 학습률(learning rate)을 설정합니다.\n","        \"per_device_train_batch_size\": batch,  # 각 디바이스(예: GPU)에서 한 번에 학습할 데이터 배치의 크기를 설정합니다. (50)\n","        \"per_device_eval_batch_size\": batch,   # 평가 시 사용할 배치 크기를 설정합니다. (32)\n","        \"warmup_ratio\": 0.1,                # 학습 초기에 학습률을 천천히 증가시키는 비율을 설정합니다.\n","        \"weight_decay\": 0.01,               # 가중치 감쇠(weight decay) 값을 설정합니다. (과적합 방지를 위해 사용)\n","        \"lr_scheduler_type\": 'cosine_with_restarts',      # 학습률 스케줄러 유형을 'cosine'으로 설정합니다.\n","        \"optim\": 'adamw_torch',             # 옵티마이저(optimizer)로 AdamW를 사용합니다.\n","        \"gradient_accumulation_steps\": 1,   # 기울기(gradient) 축적을 위한 스텝 수를 설정합니다. (1이면 축적 없이 바로 업데이트)\n","        \"evaluation_strategy\": 'epoch',     # 평가를 언제 수행할지 설정합니다. ('epoch'는 각 에폭 종료 시 평가)\n","        \"save_strategy\": 'epoch',           # 모델을 저장할 시점을 설정합니다. ('epoch'는 각 에폭 종료 시 저장)\n","        \"save_total_limit\": 7,              # 최대 저장할 체크포인트 수를 설정합니다. (가장 최근 7개만 유지)\n","        \"fp16\": True,                       # 반정밀도(floating point 16) 연산을 사용할지 설정합니다. (True이면 메모리 절약 및 속도 향상)\n","        \"load_best_model_at_end\": True,     # 학습이 종료될 때 가장 성능이 좋은 모델을 불러옵니다.\n","        \"seed\": 42,                         # 랜덤 시드를 설정하여 실험의 재현성을 보장합니다.\n","        \"logging_dir\": \"./logs\",            # 학습 로그를 저장할 디렉터리를 설정합니다.\n","        \"logging_strategy\": \"epoch\",        # 로그를 언제 기록할지 설정합니다. ('epoch'는 각 에폭 종료 시 기록)\n","        \"predict_with_generate\": True,      # 평가 시 텍스트 생성을 수행할지 설정합니다.\n","        \"generation_max_length\": 200,       # 텍스트 생성 시 최대 길이를 설정합니다. (100 토큰)\n","        \"do_train\": True,                   # 모델을 학습할지 여부를 설정합니다. (True로 설정)\n","        \"do_eval\": True,                    # 모델을 평가할지 여부를 설정합니다. (True로 설정)\n","        \"early_stopping_patience\": 3,       # 조기 종료를 위한 인내 기간(몇 번의 에폭 동안 성능 개선이 없으면 종료)을 설정합니다. (3)\n","        \"early_stopping_threshold\": 0.001,  # 조기 종료를 위한 성능 개선 최소 임계값을 설정합니다. (0.001)\n","        \"report_to\": \"wandb\"                # (선택 사항) wandb를 사용하여 학습 과정을 보고할지 설정합니다.\n","    },\n","    \"inference\": {\n","        \"ckt_path\": \"./\",  # 학습된 모델의 체크포인트 파일 경로를 설정합니다.\n","        \"result_path\": \"./prediction/\",  # 추론 결과를 저장할 경로를 설정합니다.\n","        \"no_repeat_ngram_size\": 4,  # 생성된 텍스트에서 동일한 n-gram이 반복되지 않도록 설정합니다. (2-gram 기준)\n","        \"early_stopping\": True,  # 조기 종료를 사용할지 여부를 설정합니다.\n","        \"generate_max_length\": 200,  # 생성 텍스트의 최대 길이를 설정합니다. (100 토큰)\n","        \"num_beams\": 5,  # 빔 서치(beam search) 시 사용할 빔 수를 설정합니다. 1~5까지 가능함. (4)\n","        \"batch_size\": batch,  # 추론 시 사용할 배치 크기를 설정합니다. (32)\n","        # 모델 생성 결과에서 불필요한 토큰들을 제거합니다.\n","        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n","    },\n","    \"tokenizer\": {\n","        \"encoder_max_len\": 1024,  # 입력 텍스트를 인코딩할 때 최대 길이를 설정합니다. (512 토큰)\n","        \"decoder_max_len\": 200,  # 출력 텍스트(생성된 텍스트)를 디코딩할 때 최대 길이를 설정합니다. (100 토큰)\n","        \"bos_token\": f\"{tokenizer.bos_token}\",  # 시작 토큰(beginning of sentence)을 지정합니다.\n","        \"eos_token\": f\"{tokenizer.eos_token}\",  # 끝 토큰(end of sentence)을 지정합니다.\n","        # 특정 단어들이 분해되지 않도록, special_tokens을 지정하여 토크나이저에서 처리할 때 이들 단어를 그대로 유지합니다.\n","        \"special_tokens\": [ '#Person1#',     #76737\n","                            '#Person2#',     #70211\n","                            '#Person3#',     #452\n","                            '#Person4#',     #41\n","                            '#Person5#',     #5\n","                            '#Person6#',     #9\n","                            '#Person7#',     #3\n","                            '#SSN#',         #3\n","                            '#PhoneNumber#', #203\n","                            '#Address#',     #45\n","                            '#Email#',       #17\n","                            '#CarNumber#',   #6\n","                            '#CardNumber#'   #10\n","                            '#DateOfBirth#', #8\n","                            '#PassportNumber#']  #7\n","                            # #Person 2#    띄어쓰기 오타 1개 o\n","                            # 9547,9548     #Person1      #없는 오타 2개 o\n","                            # 9547,9548     #Person2      #없는 오타 2개 o\n","                            # 9750,9779     Person1#      #없는 오타 2개 o\n","                            # 420           #PhoneNumber  #없는 오타 1개 o\n","                            # #Person#      숫자 없는 오타 1개 o\n","                            # 839      #사람1만기 시 계정 갱신 o\n","                            # 1033sum  이 사람2#에게 내일 아침 o\n","                            # 1125     사람1#: 제니, 이번 o\n","                            # 1133     사람2#은 그 기간 동 o\n","                            # 1030     이 사람2#에게 내일 o\n","                            # 1142     사람1#: 실례합니다. 저는 o\n","                            # 1199     사람1#은 시험에 대한 준비가 된 o\n","                            # 1213     #하지만 장기간의 o\n","                            # 1236     #고객님, 크루즈 컨트롤에 o\n","                            # 1250     ##여기 있습니다. 스티븐 o\n","                            # 1266     #고객님, 저희는 고객이 화나 o\n","                            # 1278     #고객님, 죄송합니다만 계 o\n","                            # 1281     #잠깐만요, 버전 7 o\n","                            # 1283     #어디 보자. 네, 그런 방 o\n","                            # 1301     #샐러드용 드레싱은 o\n","                            # 1302     #페리에와 짐 빔 세 o\n","                            # 1306     #나 부엌에 있어. . . o\n","                            # 1322     #여기서 만나서 반갑 o\n","                            # 1547     #작은 걸로 주세 o\n","                            # 1609     #여기 있습니다. o\n","                            # 정상 8320   음표는 G#이라고 써있어.\n","                            # 10370    회사 #에서 기술자로 근  o\n","                            # 11716    ##: 안녕, 프란시스   #이 두개 o\n","                            # 4001     (Person A가 탈의실에서 나옴) 스웨터는 어떠셨나요? o\n","                            # 2255     전화번호는 610-555-1234입니다. o\n","                            # 2719     네, 488-6361입니다. 3시까지 저 o\n","                            # 2980     전화번호는 513-3284입니다. o\n","    },\n","    # (선택 사항) wandb 설정: wandb 홈페이지에서 받은 entity, project, run_name 정보를 설정합니다.\n","    \"wandb\": {\n","            \"entity\": \"kkukky-empty\",  # wandb에서 실험을 기록할 엔티티(entity)를 설정합니다.\n","            \"project\": \"NLP2\",  # wandb 프로젝트 이름을 설정합니다.\n","            \"name\": title # wandb에서 실행(run) 이름을 설정합니다.\n","    }\n","}\n","\n","\n","### 변수 적용 간편화를 위해 코드 옮김\n","\n","# 모델의 구성 정보를 YAML 파일로 저장합니다.\n","config_path = \"./config_bart.yaml\"\n","with open(config_path, \"w\") as file:\n","    yaml.dump(config_data, file, allow_unicode=True)\n","\n","# 저장된 config 파일을 불러옵니다.\n","config_path = \"./config_bart.yaml\"\n","with open(config_path, \"r\") as file:\n","    config = yaml.safe_load(file)\n","\n","# 불러온 config 파일의 전체 내용을 확인합니다.\n","# pprint(config)\n"]},{"cell_type":"markdown","metadata":{"id":"HtMdEpI3uU6_"},"source":["### 4) 데이터 확인"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rUcvcVjqw9kZ","executionInfo":{"status":"ok","timestamp":1725960160965,"user_tz":-540,"elapsed":32074,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"02639d25-8a90-4f05-cc47-02e7814615ba"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"RqQ95T6ouU6_","executionInfo":{"status":"ok","timestamp":1725960163816,"user_tz":-540,"elapsed":2853,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"537b131f-d41b-4549-b7f8-0b5cd7bae8a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AILAB/NLP/data\n"]},{"output_type":"execute_result","data":{"text/plain":["             fname                                           dialogue  \\\n","12452  train_12455  #Person1#: 실례합니다. 맨체스터 출신의 그린 씨이신가요?\\n#Person2...   \n","12453  train_12456  #Person1#: 이윙 씨가 우리가 컨퍼런스 센터에 오후 4시에 도착해야 한다고 ...   \n","12454  train_12457  #Person1#: 오늘 어떻게 도와드릴까요?\\n#Person2#: 차를 빌리고 싶...   \n","12455  train_12458  #Person1#: 오늘 좀 행복해 보이지 않아. 무슨 일 있어?\\n#Person2...   \n","12456  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n","\n","                                                 summary     topic  \n","12452  탄 링은 흰머리와 수염으로 쉽게 인식되는 그린 씨를 만나 호텔로 데려갈 예정입니다....  누군가를 태우다  \n","12453  #Person1#과 #Person2#는 이윙 씨가 늦지 않도록 요청했기 때문에 컨퍼...   컨퍼런스 센터  \n","12454       #Person2#는 #Person1#의 도움으로 5일 동안 소형 차를 빌립니다.      차 렌트  \n","12455  #Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 ...        실직  \n","12456  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...      짐 싸기  "],"text/html":["\n","  <div id=\"df-ca08b882-eef3-4ff0-9475-6ca6c9af2b49\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fname</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","      <th>topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12452</th>\n","      <td>train_12455</td>\n","      <td>#Person1#: 실례합니다. 맨체스터 출신의 그린 씨이신가요?\\n#Person2...</td>\n","      <td>탄 링은 흰머리와 수염으로 쉽게 인식되는 그린 씨를 만나 호텔로 데려갈 예정입니다....</td>\n","      <td>누군가를 태우다</td>\n","    </tr>\n","    <tr>\n","      <th>12453</th>\n","      <td>train_12456</td>\n","      <td>#Person1#: 이윙 씨가 우리가 컨퍼런스 센터에 오후 4시에 도착해야 한다고 ...</td>\n","      <td>#Person1#과 #Person2#는 이윙 씨가 늦지 않도록 요청했기 때문에 컨퍼...</td>\n","      <td>컨퍼런스 센터</td>\n","    </tr>\n","    <tr>\n","      <th>12454</th>\n","      <td>train_12457</td>\n","      <td>#Person1#: 오늘 어떻게 도와드릴까요?\\n#Person2#: 차를 빌리고 싶...</td>\n","      <td>#Person2#는 #Person1#의 도움으로 5일 동안 소형 차를 빌립니다.</td>\n","      <td>차 렌트</td>\n","    </tr>\n","    <tr>\n","      <th>12455</th>\n","      <td>train_12458</td>\n","      <td>#Person1#: 오늘 좀 행복해 보이지 않아. 무슨 일 있어?\\n#Person2...</td>\n","      <td>#Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 ...</td>\n","      <td>실직</td>\n","    </tr>\n","    <tr>\n","      <th>12456</th>\n","      <td>train_12459</td>\n","      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n","      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n","      <td>짐 싸기</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca08b882-eef3-4ff0-9475-6ca6c9af2b49')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ca08b882-eef3-4ff0-9475-6ca6c9af2b49 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ca08b882-eef3-4ff0-9475-6ca6c9af2b49');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-428e0dc2-c24d-4515-ace4-4c23d0f45425\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-428e0dc2-c24d-4515-ace4-4c23d0f45425')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-428e0dc2-c24d-4515-ace4-4c23d0f45425 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"train_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"train_12456\",\n          \"train_12459\",\n          \"train_12457\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dialogue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"#Person1#: \\uc774\\uc719 \\uc528\\uac00 \\uc6b0\\ub9ac\\uac00 \\ucee8\\ud37c\\ub7f0\\uc2a4 \\uc13c\\ud130\\uc5d0 \\uc624\\ud6c4 4\\uc2dc\\uc5d0 \\ub3c4\\ucc29\\ud574\\uc57c \\ud55c\\ub2e4\\uace0 \\ud588\\uc8e0?\\n#Person2#: \\ub124, \\uadf8\\ub294 \\ud2b9\\ud788 \\uc6b0\\ub9ac\\uac00 \\ub2a6\\uc9c0 \\uc54a\\ub3c4\\ub85d \\uc694\\uccad\\ud588\\uc2b5\\ub2c8\\ub2e4. \\uc6b0\\ub9ac \\ub3d9\\uc694\\ud06c \\uc9c0\\uc0ac\\uc5d0\\uc11c \\uba87\\uba87 \\uc0ac\\ub78c\\ub4e4\\uc774 \\uc624\\ub294\\ub370, \\uadf8\\ub4e4\\uc5d0\\uac8c \\uc88b\\uc740 \\uc778\\uc0c1\\uc744 \\ub0a8\\uae30\\uace0 \\uc2f6\\uc5b4\\ud569\\ub2c8\\ub2e4. \\uc5b4\\ub5bb\\uac8c \\uac00\\uc2e4 \\uac74\\uac00\\uc694?\\n#Person1#: \\uc81c \\ucc28\\ub97c \\ud0c0\\uace0 \\uac00\\ub824\\uace0 \\ud588\\ub294\\ub370, \\uace0\\uc18d\\ub3c4\\ub85c\\uc5d0 \\uacf5\\uc0ac\\uac00 \\uc788\\uc5b4\\uc11c \\uc9c0\\ud558\\ucca0\\uc744 \\uc774\\uc6a9\\ud560 \\uac83 \\uac19\\uc2b5\\ub2c8\\ub2e4. \\ub2f9\\uc2e0\\uc740\\uc694?\\n#Person2#: \\uc800\\ub3c4 \\uc9c0\\ud558\\ucca0\\uc744 \\uc774\\uc6a9\\ud560 \\uc608\\uc815\\uc785\\ub2c8\\ub2e4. \\uac19\\uc774 \\uac00\\ub294 \\uac74 \\uc5b4\\ub5a8\\uae4c\\uc694? \\uc800\\ub294 \\ucee8\\ud37c\\ub7f0\\uc2a4 \\uc13c\\ud130\\uc5d0 \\ud55c \\ubc88\\ubc16\\uc5d0 \\uac00\\ubcf8 \\uc801\\uc774 \\uc5c6\\uc5b4\\uc11c \\uae38\\uc744 \\uc798 \\ubabb \\ucc3e\\uc744 \\uac83 \\uac19\\uc544\\uc694.\",\n          \"#Person1#: \\uc5c4\\ub9c8, \\ub2e4\\uc74c \\ud1a0\\uc694\\uc77c\\uc5d0 \\uc774 \\uc0bc\\ucd0c\\ub124 \\uac00\\uc871\\uc744 \\ubc29\\ubb38\\ud558\\uae30 \\uc704\\ud574 \\ube44\\ud589\\uae30\\ub97c \\ud0c0\\uace0 \\uac08 \\uac70\\uc608\\uc694. \\uc624\\ub298 \\uac00\\ubc29\\uc744 \\uc2f8\\ub3c4 \\ub420\\uae4c\\uc694?\\n#Person2#: \\ub124, \\uadf8\\uac8c \\uc88b\\uc744 \\uac83 \\uac19\\uc544\\uc694.\\n#Person1#: \\uc54c\\uaca0\\uc5b4\\uc694. \\uc5b4\\ub5a4 \\uc637\\uc744 \\uac00\\uc838\\uac00\\uc57c \\ud560\\uae4c\\uc694? \\uac70\\uae30 \\ub0a0\\uc528\\uac00 \\ub354\\uc6b4 \\uac74 \\uc54c\\uace0 \\uc788\\uc5b4\\uc694.\\n#Person2#: \\ub124, \\ud558\\uc9c0\\ub9cc \\ube44\\uac00 \\ub9ce\\uc774 \\uc640\\uc694. \\ube44\\uac00 \\uc624\\uba74 \\uc6b0\\uc0b0\\uc774\\ub098 \\uc7ac\\ud0b7\\uc744 \\ube4c\\ub9b4 \\uc218 \\uc788\\uc5b4\\uc694. \\ud2f0\\uc154\\uce20\\ub9cc \\uba87 \\uc7a5 \\uc2f8\\uac00\\uc138\\uc694.\\n#Person1#: \\uc54c\\uaca0\\uc5b4\\uc694. \\uadf8\\ub7fc \\uacf5\\ud56d\\uc5d0\\uc11c \\ub204\\uac00 \\uc800\\ub97c \\ub9cc\\ub098\\ub7ec \\uc624\\ub098\\uc694?\\n#Person2#: \\uc774 \\uc0bc\\ucd0c\\uacfc \\uc655 \\uc774\\ubaa8\\ub294 \\ubc14\\uc060 \\ud14c\\ub2c8\\uae4c, \\uc0ac\\ucd0c \\uc218\\uc794\\uc774 \\ub2f9\\uc2e0\\uc744 \\ub370\\ub9ac\\ub7ec \\uac08 \\uc218 \\uc788\\uc744 \\uac70\\uc608\\uc694.\",\n          \"#Person1#: \\uc624\\ub298 \\uc5b4\\ub5bb\\uac8c \\ub3c4\\uc640\\ub4dc\\ub9b4\\uae4c\\uc694?\\n#Person2#: \\ucc28\\ub97c \\ube4c\\ub9ac\\uace0 \\uc2f6\\uc2b5\\ub2c8\\ub2e4.\\n#Person1#: \\ucc3e\\uc544\\ubcfc\\uac8c\\uc694. \\ub300\\ud615 \\ucc28, \\uc911\\ud615 \\ucc28, \\uc18c\\ud615 \\ucc28 \\uc911\\uc5d0\\uc11c \\uc120\\ud0dd\\ud558\\uc2e4 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\uc5b4\\ub5a4 \\ud06c\\uae30\\ub97c \\ucc3e\\uc73c\\uc2dc\\ub098\\uc694?\\n#Person2#: \\ub3c4\\uc2dc\\uc5d0\\uc11c \\ud63c\\uc790 \\uc5ec\\ud589\\ud560 \\uc608\\uc815\\uc774\\ub77c \\uc18c\\ud615 \\ucc28\\ub85c \\uad1c\\ucc2e\\uc2b5\\ub2c8\\ub2e4. \\ud558\\ub8e8\\uc5d0 \\uc5bc\\ub9c8\\uc778\\uac00\\uc694?\\n#Person1#: \\uc18c\\ud615 \\ucc28\\ub294 \\ud558\\ub8e8\\uc5d0 $40\\uc785\\ub2c8\\ub2e4. \\ucc28\\ub97c \\uc5bc\\ub9c8\\ub098 \\uc624\\ub798 \\ube4c\\ub9ac\\uc2e4 \\uac74\\uac00\\uc694?\\n#Person2#: 5\\uc77c \\ub3d9\\uc548\\uc785\\ub2c8\\ub2e4.\\n#Person1#: \\uc54c\\uaca0\\uc2b5\\ub2c8\\ub2e4. \\uc6b4\\uc804 \\uba74\\ud5c8\\uc99d\\uacfc \\uc2e0\\uc6a9\\uce74\\ub4dc\\ub97c \\ubcfc \\uc218 \\uc788\\uc744\\uae4c\\uc694?\\n#Person2#: \\ub124, \\uc5ec\\uae30 \\uc788\\uc2b5\\ub2c8\\ub2e4.\\n#Person1#: \\uc774 \\uce74\\ub4dc\\ub85c \\uacb0\\uc81c \\ud558\\uc2dc\\uaca0\\uc2b5\\ub2c8\\uae4c?\\n#Person2#: \\uadf8\\ub807\\uac8c \\ud574\\uc8fc\\uc138\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"#Person1#\\uacfc #Person2#\\ub294 \\uc774\\uc719 \\uc528\\uac00 \\ub2a6\\uc9c0 \\uc54a\\ub3c4\\ub85d \\uc694\\uccad\\ud588\\uae30 \\ub54c\\ubb38\\uc5d0 \\ucee8\\ud37c\\ub7f0\\uc2a4 \\uc13c\\ud130\\ub85c \\uc9c0\\ud558\\ucca0\\uc744 \\uac19\\uc774 \\ud0c0\\uae30\\ub85c \\uacc4\\ud68d\\ud588\\uc2b5\\ub2c8\\ub2e4.\",\n          \"#Person1#\\uc740 \\ub2e4\\uc74c \\ud1a0\\uc694\\uc77c\\uc5d0 \\uc774 \\uc0bc\\ucd0c\\ub124\\ub97c \\ubc29\\ubb38\\ud560 \\ub54c \\uac00\\ubc29\\uc744 \\uc5b4\\ub5bb\\uac8c \\uc2f8\\uc57c \\ud560\\uc9c0 #Person2#\\uc5d0\\uac8c \\uc870\\uc5b8\\uc744 \\uad6c\\ud569\\ub2c8\\ub2e4.\",\n          \"#Person2#\\ub294 #Person1#\\uc758 \\ub3c4\\uc6c0\\uc73c\\ub85c 5\\uc77c \\ub3d9\\uc548 \\uc18c\\ud615 \\ucc28\\ub97c \\ube4c\\ub9bd\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ucee8\\ud37c\\ub7f0\\uc2a4 \\uc13c\\ud130\",\n          \"\\uc9d0 \\uc2f8\\uae30\",\n          \"\\ucc28 \\ub80c\\ud2b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n","data_path = config['general']['data_path']\n","print(data_path)\n","\n","# train data의 구조와 내용을 확인합니다.\n","train_df = pd.read_csv(os.path.join(data_path, train))\n","train_df.tail()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"atzsUHHUuU6_","executionInfo":{"status":"ok","timestamp":1725960164606,"user_tz":-540,"elapsed":792,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"8195d5fb-6bc6-40e8-d96d-3713d28ea1ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       fname                                           dialogue  \\\n","494  dev_495  #Person1#: 이제 새해가 되어서 새로운 시작을 하려고 결심했어. \\r\\n#P...   \n","495  dev_496  #Person1#: 너, 조랑 결혼했지? \\r\\n#Person2#: 조? 무슨 말인...   \n","496  dev_497  #Person1#: 무엇을 도와드릴까요, 부인?\\r\\n#Person2#: 몇 주 동...   \n","497  dev_498  #Person1#: 안녕하세요, 아마존 고객 서비스입니다. 무엇을 도와드릴까요?\\n...   \n","498  dev_499  #Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...   \n","\n","                                               summary    topic  \n","494  #Person1#은 새해에 금연을 하고 커밍아웃하기로 결정했습니다. #Person2...       새해  \n","495  #Person1#은 #Person2#가 조와 결혼했다고 생각했다. #Person2#...  사랑에 빠지다  \n","496  #Person2#의 차에서 이상한 소리가 납니다. #Person1#는 브레이크를 교...       소음  \n","497  #Person2#님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지...   빠진 페이지  \n","498  #Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...    여름 휴가  "],"text/html":["\n","  <div id=\"df-bb59b42b-2ec9-48d1-839f-22afa4f44a45\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fname</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","      <th>topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>494</th>\n","      <td>dev_495</td>\n","      <td>#Person1#: 이제 새해가 되어서 새로운 시작을 하려고 결심했어. \\r\\n#P...</td>\n","      <td>#Person1#은 새해에 금연을 하고 커밍아웃하기로 결정했습니다. #Person2...</td>\n","      <td>새해</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>dev_496</td>\n","      <td>#Person1#: 너, 조랑 결혼했지? \\r\\n#Person2#: 조? 무슨 말인...</td>\n","      <td>#Person1#은 #Person2#가 조와 결혼했다고 생각했다. #Person2#...</td>\n","      <td>사랑에 빠지다</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>dev_497</td>\n","      <td>#Person1#: 무엇을 도와드릴까요, 부인?\\r\\n#Person2#: 몇 주 동...</td>\n","      <td>#Person2#의 차에서 이상한 소리가 납니다. #Person1#는 브레이크를 교...</td>\n","      <td>소음</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>dev_498</td>\n","      <td>#Person1#: 안녕하세요, 아마존 고객 서비스입니다. 무엇을 도와드릴까요?\\n...</td>\n","      <td>#Person2#님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지...</td>\n","      <td>빠진 페이지</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>dev_499</td>\n","      <td>#Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...</td>\n","      <td>#Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...</td>\n","      <td>여름 휴가</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb59b42b-2ec9-48d1-839f-22afa4f44a45')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bb59b42b-2ec9-48d1-839f-22afa4f44a45 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bb59b42b-2ec9-48d1-839f-22afa4f44a45');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b0a5dd7b-4d1f-4b01-9a68-f71d95f3c3dd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0a5dd7b-4d1f-4b01-9a68-f71d95f3c3dd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b0a5dd7b-4d1f-4b01-9a68-f71d95f3c3dd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"val_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"dev_496\",\n          \"dev_499\",\n          \"dev_497\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dialogue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"#Person1#: \\ub108, \\uc870\\ub791 \\uacb0\\ud63c\\ud588\\uc9c0? \\r\\n#Person2#: \\uc870? \\ubb34\\uc2a8 \\ub9d0\\uc778\\uc9c0 \\ubaa8\\ub974\\uaca0\\uc5b4. \\r\\n#Person1#: \\ub124\\uac00 \\uc0ac\\ub791\\uc5d0 \\ube60\\uc84c\\ub2e4\\ub294 \\uac78 \\uae30\\uc5b5\\ud574. \\r\\n#Person2#: \\uc544, \\ucc98\\uc74c \\ub9cc\\ub0ac\\uc744 \\ub54c \\uadf8\\uc5d0\\uac8c \\ud638\\uac10\\uc744 \\uac00\\uc84c\\uc5c8\\uc5b4. \\ud558\\uc9c0\\ub9cc \\ub9c8\\uc74c\\uc774 \\uac08\\ud321\\uc9c8\\ud321\\ud574.\\r\\n#Person1#: \\ubb34\\uc2a8 \\ub9d0\\uc778\\uc9c0 \\uc804\\ud600 \\ubaa8\\ub974\\uaca0\\ub124.\",\n          \"#Person1#: \\uc5ec\\ub984\\uc774 \\ub2e4 \\ub418\\uc5b4\\uac04\\ub2e4\\ub294 \\uac8c \\ubbff\\uae30\\uc9c0 \\uc54a\\uc544.\\r\\n#Person2#: \\uc751, \\uc54c\\uc544. \\uc774\\ubc88 \\ud574\\ub294 \\uc815\\ub9d0 \\ube68\\ub9ac \\uac14\\uc5b4.\\r\\n#Person1#: \\uc774\\ubc88 \\uc5ec\\ub984 \\ud734\\uac00\\uc5d0 \\ubb50 \\ud560 \\uac70\\uc57c?\\r\\n#Person2#: \\ub098\\ub294 \\ud68c\\uc0ac\\uc5d0\\uc11c \\uc77c\\ud560 \\uac70\\uc57c.\\r\\n#Person1#: \\ud68c\\uc0ac? \\uadf8\\uac8c \\ubb50\\uc57c? \\ubb34\\uc2a8 \\uc77c\\uc744 \\ud558\\ub294 \\uac70\\uc57c?\\r\\n#Person2#: \\uc6b0\\ub9ac\\ub294 \\ud30c\\ud2f0\\ub97c \\ub3c4\\uc640. \\uc6b0\\ub9ac \\ud68c\\uc0ac\\ub294 \\uc74c\\uc2dd\\uc744 \\uc900\\ube44\\ud558\\uace0 \\uc81c\\uacf5\\ud558\\uace0, \\ubcf4\\ud1b5 \\ub2e4\\ub978 \\ud68c\\uc0ac\\uc5d0\\uc11c \\uc74c\\uc545\\uc744 \\uc81c\\uacf5\\ud574.\\r\\n#Person1#: \\ub124\\uac00 \\uc694\\ub9ac\\ub97c \\ud560 \\uc904 \\ubab0\\ub790\\uc5b4.\\r\\n#Person2#: \\ub098\\ub294 \\uc694\\ub9ac\\ub97c \\ud560 \\ud544\\uc694\\uac00 \\uc5c6\\uc5b4. \\ub098\\ub294 \\uadf8\\uc800 \\uc870\\uc218\\uc77c \\ubfd0\\uc774\\uc57c.\\r\\n#Person1#: \\uc5b8\\uc81c \\uc2dc\\uc791\\ud574?\\r\\n#Person2#: \\ub0b4\\uc77c\\uc774\\uc57c. \\uc6b0\\ub9ac\\ub294 \\uc0dd\\uc77c \\ud30c\\ud2f0\\ub97c \\ub3c4\\uc640\\uc904 \\uac70\\uc57c. \\uadf8\\ub9ac\\uace0 \\ub300\\uac00\\uc871\\uc774 \\ubaa8\\uc77c\\uac70\\uc57c.\\r\\n#Person1#: \\uadf8\\ub7fc, \\ub108\\ub294 \\uc815\\ud655\\ud788 \\ubb58 \\ud558\\ub294 \\uac70\\uc57c?\\r\\n#Person2#: \\ud30c\\ud2f0\\uac00 \\uc2dc\\uc791\\ud558\\uae30 \\uc804\\uc5d0, \\ub098\\ub294 \\ubaa8\\ub4e0 \\uac83\\uc744 \\uc900\\ube44\\ud558\\ub294 \\uac83\\uc744 \\ub3c4\\uc640. \\uc74c\\uc2dd\\uc744 \\uac00\\uc838\\ub2e4 \\ub193\\uace0, \\ud14c\\uc774\\ube14\\uc744 \\uc815\\ub9ac\\ud558\\uace0, \\uc608\\uc058\\uac8c \\ubcf4\\uc774\\uac8c \\ud558\\ub294 \\uac70\\uc9c0.\\r\\n#Person1#: \\uaf64 \\uc26c\\uc6cc \\ubcf4\\uc774\\ub124.\\r\\n#Person2#: \\uadf8\\uac74 \\uc77c\\ubd80\\uc77c \\ubfd0\\uc774\\uc57c. \\ud30c\\ud2f0 \\ub3c4\\uc911\\uc5d0\\ub294 \\uc190\\ub2d8\\ub4e4\\uc5d0\\uac8c \\uc74c\\uc2dd\\uacfc \\uc74c\\ub8cc\\ub97c \\uc81c\\uacf5\\ud574\\uc57c \\ud574.\\r\\n#Person1#: \\uadf8\\ub798\\ub3c4 \\uc0ac\\ub78c\\ub4e4\\uc744 \\ub9cc\\ub0a0 \\uc218 \\uc788\\uc5b4\\uc11c \\uc88b\\uaca0\\ub2e4.\\r\\n#Person2#: \\uc751, \\uadf8\\ub9ac\\uace0 \\ud30c\\ud2f0\\uac00 \\ub05d\\ub098\\uba74 \\uccad\\uc18c\\ub97c \\ub3c4\\uc640.\\r\\n#Person1#: \\uc73d, \\uc124\\uac70\\uc9c0\\ud558\\ub294 \\uac74 \\uc2eb\\uc5b4.\\r\\n#Person2#: \\uc544, \\ub098\\ub294 \\uc124\\uac70\\uc9c0\\ub97c \\uc548 \\ud574. \\ub2e4\\ub978 \\uc0ac\\ub78c\\uc774 \\ud574. \\ub098\\ub294 \\uadf8\\ub0e5 \\ubaa8\\ub4e0 \\uac83\\uc744 \\ud2b8\\ub7ed\\uc5d0 \\ub123\\uc744 \\ubfd0\\uc774\\uc57c.\\r\\n#Person1#: \\uadf8\\ub807\\uac8c \\ub098\\uc058\\uc9c0 \\uc54a\\ub124. \\uaf64 \\uba4b\\uc9c4 \\uc9c1\\uc5c5 \\uac19\\uc544.\",\n          \"#Person1#: \\ubb34\\uc5c7\\uc744 \\ub3c4\\uc640\\ub4dc\\ub9b4\\uae4c\\uc694, \\ubd80\\uc778?\\r\\n#Person2#: \\uba87 \\uc8fc \\ub3d9\\uc548 \\ucc28\\uc5d0\\uc11c \\uc774\\uc0c1\\ud55c \\uc18c\\ub9ac\\uac00 \\ub098\\uc11c \\uc624\\ub298 \\ud55c\\ubc88 \\ubd10\\uc8fc\\uc2e4 \\uc218 \\uc788\\uc744\\uae4c\\uc694?\\r\\n#Person1#: \\uc5b4\\ub5a4 \\uc885\\ub958\\uc758 \\uc18c\\ub9ac\\uc778\\uac00\\uc694?\\r\\n#Person2#: \\ubc14\\ud034\\uc5d0\\uc11c \\ubb54\\uac00\\uac00 \\uc190\\uc0c1\\ub418\\ub294 \\uac83 \\uac19\\uc740 \\uc18c\\ub9ac\\uac00 \\ub098\\uc694. \\uc81c\\uac00 \\uc18d\\ub3c4\\ub97c \\uc904\\uc77c \\ub54c\\ub9cc \\uadf8\\ub7f0 \\uc18c\\ub9ac\\uac00 \\ub098\\uc694.\\r\\n#Person1#: \\uc640\\uc6b0, \\ube0c\\ub808\\uc774\\ud06c\\ub97c \\uc0c8\\ub85c \\uad50\\uccb4\\ud574\\uc57c \\ud560 \\uac83 \\uac19\\ub124\\uc694. \\ucc28\\ub97c \\ub0b4\\uc77c\\uae4c\\uc9c0 \\uc800\\ud76c\\uc5d0\\uac8c \\ub9e1\\uaca8\\uc57c \\ud560 \\uac83 \\uac19\\uc544\\uc694.\\r\\n#Person2#: \\uc774\\ub7f0, \\uc624\\ub298 \\uc624\\ud6c4\\uc5d0 \\ucc28\\ub97c \\ub3cc\\ub824\\ubc1b\\uc744 \\uc218 \\uc788\\uc744 \\uc904 \\uc54c\\uc558\\uc5b4\\uc694.\\r\\n#Person1#: \\uc720\\uac10\\uc2a4\\ub7fd\\uac8c\\ub3c4, \\ubd80\\ud488\\uc744 \\uc8fc\\ubb38\\ud574\\uc57c \\ud558\\uace0 \\uadf8\\uac83\\ub4e4\\uc774 \\ub3c4\\ucc29\\ud558\\uae30 \\uc804\\uc5d0\\ub294 \\uc791\\uc5c5\\uc744 \\uc2dc\\uc791\\ud560 \\uc218 \\uc5c6\\uc5b4\\uc694. \\uc9c0\\uae08 \\uc8fc\\ubb38\\ud558\\uba74 \\uc624\\ud6c4\\ub098 \\ub0b4\\uc77c \\uc544\\uce68\\uc5d0\\ub294 \\ub3c4\\ucc29\\ud560 \\uac83\\uc785\\ub2c8\\ub2e4.\\r\\n#Person2#: \\uc54c\\uaca0\\uc2b5\\ub2c8\\ub2e4. \\uadf8\\ub7fc \\ub0b4\\uc77c \\uc544\\uce68\\uc5d0 \\ucc28\\ub97c \\ub2e4\\uc2dc \\uac00\\uc838\\uc624\\ub294 \\uac8c \\uc5b4\\ub5a8\\uae4c\\uc694? \\uc624\\ub298 \\ubc24\\uc5d0 \\uaf2d \\ubcf4\\uace0 \\uc2f6\\uc740 \\uacf5\\uc5f0\\uc774 \\uc2dc\\ub0b4\\uc5d0 \\uc788\\uac70\\ub4e0\\uc694.\\r\\n#Person1#: \\uadf8\\uac74 \\uc88b\\uc740 \\uc0dd\\uac01\\uc774 \\uc544\\ub2cc \\uac83 \\uac19\\uc544\\uc694. \\ub2f9\\uc2e0\\uc740 \\uc774 \\ucc28\\ub97c \\uc6b4\\uc804\\ud558\\uba74\\uc11c \\ubaa9\\uc228\\uc744 \\uac78\\uace0 \\uc788\\uc5b4\\uc694. \\uc81c\\uac00 \\ub2f9\\uc2e0\\uc774\\ub77c\\uba74 \\ubc84\\uc2a4 \\uc2dc\\uac04\\ud45c\\ub97c \\ud655\\uc778\\ud574 \\ubcfc \\uac83\\uc785\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"#Person1#\\uc740 #Person2#\\uac00 \\uc870\\uc640 \\uacb0\\ud63c\\ud588\\ub2e4\\uace0 \\uc0dd\\uac01\\ud588\\ub2e4. #Person2#\\ub294 \\ubd80\\uc778\\ud588\\ub2e4.\",\n          \"#Person2#\\ub294 #Person1#\\uc5d0\\uac8c \\uc5ec\\ub984 \\ud734\\uac00 \\ub3d9\\uc548 \\ud30c\\ud2f0\\ub97c \\ub3c4\\uc640\\uc8fc\\ub294 \\ud68c\\uc0ac\\uc5d0\\uc11c \\uc77c\\ud560 \\uac83\\uc774\\ub77c\\uace0 \\ub9d0\\ud55c\\ub2e4. #Person1#\\ub294 \\uadf8\\uac83\\uc774 \\uba4b\\uc9c4 \\uc9c1\\uc5c5\\uc774\\ub77c\\uace0 \\uc0dd\\uac01\\ud55c\\ub2e4.\",\n          \"#Person2#\\uc758 \\ucc28\\uc5d0\\uc11c \\uc774\\uc0c1\\ud55c \\uc18c\\ub9ac\\uac00 \\ub0a9\\ub2c8\\ub2e4. #Person1#\\ub294 \\ube0c\\ub808\\uc774\\ud06c\\ub97c \\uad50\\uccb4\\ud574\\uc57c \\ud560 \\uac83\\uc73c\\ub85c \\uc0dd\\uac01\\ud558\\uc9c0\\ub9cc, #Person1#\\ub294 \\ub0b4\\uc77c\\uae4c\\uc9c0 \\uadf8\\uac83\\uc744 \\uace0\\uce60 \\uc218 \\uc5c6\\uc2b5\\ub2c8\\ub2e4. #Person2#\\ub294 \\uc624\\ub298 \\ubc24\\uc5d0 \\uacf5\\uc5f0\\uc744 \\ubcf4\\ub7ec \\uac00\\uace0 \\uc2f6\\uc5b4\\ud569\\ub2c8\\ub2e4; #Person1#\\ub294 #Person2#\\uc5d0\\uac8c \\ubc84\\uc2a4\\ub97c \\uc774\\uc6a9\\ud560 \\uac83\\uc744 \\uc81c\\uc548\\ud569\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\uc5d0 \\ube60\\uc9c0\\ub2e4\",\n          \"\\uc5ec\\ub984 \\ud734\\uac00\",\n          \"\\uc18c\\uc74c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"source":["# validation data의 구조와 내용을 확인합니다.\n","val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n","val_df.tail()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Tji2nNySuU6_","executionInfo":{"status":"ok","timestamp":1725960164606,"user_tz":-540,"elapsed":7,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"61c95d61-080d-4d8d-92e7-e66db6dc47aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        fname                                           dialogue\n","494  test_495  #Person1#: 헤이, 찰리, 학교 끝나고 우리 집에 와서 나랑 비디오 게임 할...\n","495  test_496  #Person1#: 어떻게 컨트리 음악에 관심을 가지게 되었나요?\\r\\n#Perso...\n","496  test_497  #Person1#: 실례합니다, 앨리스. 이곳을 사용해본 적이 없는데, 기계를 어떻...\n","497  test_498  #Person1#: 매튜? 안녕!\\r\\n#Person2#: 스티브! 오랜만이네! 얼...\n","498  test_499  #Person1#: 헤이, 벳시, 좋은 소식 들었어?\\n#Person2#: 아니, ..."],"text/html":["\n","  <div id=\"df-4a69b5c2-9006-4e24-a624-41271802625d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fname</th>\n","      <th>dialogue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>494</th>\n","      <td>test_495</td>\n","      <td>#Person1#: 헤이, 찰리, 학교 끝나고 우리 집에 와서 나랑 비디오 게임 할...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>test_496</td>\n","      <td>#Person1#: 어떻게 컨트리 음악에 관심을 가지게 되었나요?\\r\\n#Perso...</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>test_497</td>\n","      <td>#Person1#: 실례합니다, 앨리스. 이곳을 사용해본 적이 없는데, 기계를 어떻...</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>test_498</td>\n","      <td>#Person1#: 매튜? 안녕!\\r\\n#Person2#: 스티브! 오랜만이네! 얼...</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>test_499</td>\n","      <td>#Person1#: 헤이, 벳시, 좋은 소식 들었어?\\n#Person2#: 아니, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a69b5c2-9006-4e24-a624-41271802625d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4a69b5c2-9006-4e24-a624-41271802625d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4a69b5c2-9006-4e24-a624-41271802625d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-df744cbb-7900-45e3-88eb-3e54fb1c929d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df744cbb-7900-45e3-88eb-3e54fb1c929d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-df744cbb-7900-45e3-88eb-3e54fb1c929d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"test_496\",\n          \"test_499\",\n          \"test_497\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dialogue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"#Person1#: \\uc5b4\\ub5bb\\uac8c \\ucee8\\ud2b8\\ub9ac \\uc74c\\uc545\\uc5d0 \\uad00\\uc2ec\\uc744 \\uac00\\uc9c0\\uac8c \\ub418\\uc5c8\\ub098\\uc694?\\r\\n#Person2#: \\uc544, \\uc81c \\uc544\\ub0b4\\uc640 \\uc81c\\uac00 \\ucc98\\uc74c\\uc73c\\ub85c \\ub808\\ucf54\\ub4dc \\ud50c\\ub808\\uc774\\uc5b4\\ub97c \\uad6c\\uc785\\ud588\\uc744 \\ub54c\\uc600\\uc2b5\\ub2c8\\ub2e4. \\uc6b0\\ub9ac\\ub294 \\ubaa8\\ub4e0 \\uc885\\ub958\\uc758 \\ub808\\ucf54\\ub4dc\\ub97c \\uc0ac\\uae30 \\uc2dc\\uc791\\ud588\\uace0, \\uace7, \\uc800\\ub294 \\ub2e4\\ub978 \\uc5b4\\ub5a4 \\uc885\\ub958\\ubcf4\\ub2e4\\ub3c4 \\ucee8\\ud2b8\\ub9ac \\uc74c\\uc545 \\ub808\\ucf54\\ub4dc\\ub97c \\ub354 \\ub9ce\\uc774 \\uc0ac\\uace0 \\uc788\\ub2e4\\ub294 \\uac83\\uc744 \\ubc1c\\uacac\\ud588\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person1#: \\uc5b4\\ub5bb\\uac8c \\ub77c\\ub514\\uc624 \\ubc29\\uc1a1\\uad6d\\uc5d0\\uc11c \\uc77c\\ud558\\uae30 \\uc2dc\\uc791\\ud588\\ub098\\uc694?\\r\\n#Person2#: \\ucee8\\ud2b8\\ub9ac \\uc74c\\uc545\\uc758 \\ub77c\\ub514\\uc624 \\ud504\\ub85c\\uadf8\\ub7a8\\uc774 \\uc788\\uc5b4\\uc57c \\ud55c\\ub2e4\\uace0 \\uc0dd\\uac01\\ud574\\uc11c CBC\\uc5d0 \\uac00\\uc11c \\uc81c\\uc548\\ud588\\uc2b5\\ub2c8\\ub2e4. \\uadf8\\uac8c \\uc6b0\\ub9ac\\uac00 '\\uace8\\ub4e0 \\ucee8\\ud2b8\\ub9ac \\ud0c0\\uc784'\\uc774\\ub77c\\ub294 \\ud504\\ub85c\\uadf8\\ub7a8\\uc744 \\uc2dc\\uc791\\ud558\\uac8c \\ub41c \\uacc4\\uae30\\uc600\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person1#: \\uadf8\\ub7f0 \\ub2e4\\uc74c \\uadf8 \\ub178\\ub798\\ub4e4\\uc758 \\ubc30\\uacbd\\uc744 \\uc124\\uba85\\ud558\\ub294 \\uae30\\uc0ac\\ub97c \\uc4f0\\ub77c\\ub294 \\uc694\\uccad\\uc744 \\ubc1b\\uc558\\ub098\\uc694.\\r\\n#Person2#: \\ub124, \\uadf8\\ub7f0\\ub370 \\uace7 \\uc815\\ubcf4\\ub97c \\ucc3e\\uae30 \\uc704\\ud574 \\ub3c4\\uc11c\\uad00\\uc5d0 \\ub2ec\\ub824\\uac00\\ub294 \\uac83\\uc5d0 \\uc9c0\\ucce4\\uc2b5\\ub2c8\\ub2e4. \\uadf8\\ub798\\uc11c \\ucee8\\ud2b8\\ub9ac \\uc74c\\uc545 \\ucc45\\uc744 \\uc0ac\\uae30 \\uc2dc\\uc791\\ud558\\uace0 \\uc81c \\uc790\\uc2e0\\uc758 \\ub3c4\\uc11c\\uad00\\uc744 \\ub9cc\\ub4e4\\uae30 \\uc2dc\\uc791\\ud588\\uc2b5\\ub2c8\\ub2e4.\",\n          \"#Person1#: \\ud5e4\\uc774, \\ubcb3\\uc2dc, \\uc88b\\uc740 \\uc18c\\uc2dd \\ub4e4\\uc5c8\\uc5b4?\\n#Person2#: \\uc544\\ub2c8, \\ud504\\ub7ad\\ud06c, \\ubabb \\ub4e4\\uc5c8\\uc5b4. \\ubb34\\uc2a8 \\uc77c\\uc774\\uc57c?\\n#Person1#: \\ub098 \\ubc29\\uae08 \\uc2b9\\uc9c4\\ud588\\uc5b4. \\uadf8\\ub9ac\\uace0 \\uce5c\\uad6c\\ub4e4 \\ubaa8\\ub450\\ub97c \\uc704\\ud55c \\ud070 \\ud30c\\ud2f0\\ub97c \\uc5f4\\ub824\\uace0 \\ud574. \\ub108\\ub3c4 \\uc640\\uc8fc\\uba74 \\uc88b\\uaca0\\uc5b4.\\n#Person2#: \\uc640\\uc6b0, \\uc815\\ub9d0 \\uace0\\ub9c8\\uc6cc. \\ud30c\\ud2f0\\ub294 \\uc5b8\\uc81c\\uc57c?\\n#Person1#: \\ud1a0\\uc694\\uc77c\\uc5d0 \\ud558\\ub824\\uace0 \\uc0dd\\uac01 \\uc911\\uc774\\uc57c. 150\\uba85 \\uc815\\ub3c4 \\uc62c \\uac70\\ub77c\\uace0 \\uae30\\ub300\\ud558\\uace0 \\uc788\\uc5b4.\\n#Person2#: \\uc640\\uc6b0, \\uc815\\ub9d0 \\ub9ce\\ub124. \\uc774\\uac74 \\ubd84\\uba85\\ud788 \\ud070 \\uc2b9\\uc9c4\\uc774\\uaca0\\ub124. \\ub098\\ub3c4 \\uac00\\uace0 \\uc2f6\\uc5b4. \\uc7ac\\ubbf8\\uc788\\uc744 \\uac83 \\uac19\\uc544.\\n#Person1#: \\uc624, \\uc88b\\uc544. \\uc0ac\\ub78c\\uc774 \\ub9ce\\uc744\\uc218\\ub85d \\uc88b\\uc544. \\uc774\\uac74 \\uc815\\ub9d0\\ub85c \\ub098\\uc5d0\\uac8c \\ud070 \\uc77c\\uc774\\uc57c. \\uc774\\uc81c \\uc544\\ub0b4\\uac00 \\ud56d\\uc0c1 \\uc6d0\\ud588\\ub358 \\uc0c8 \\uc9d1\\uc744 \\uc0b4 \\uc218 \\uc788\\uac8c \\ub410\\uc5b4. \\ub098\\ub294 \\ub2e8\\uc9c0 \\ub108\\ubb34 \\ub9ce\\uc740 \\uc2dc\\uac04\\uc744 \\ub4e4\\uc77c \\ud544\\uc694\\uac00 \\uc5c6\\uc5c8\\uc73c\\uba74 \\uc88b\\uaca0\\uc5b4. \\uac00\\uc871\\uacfc\\uc758 \\uc2dc\\uac04\\uc744 \\ub108\\ubb34 \\ub9ce\\uc774 \\uc783\\uace0 \\uc2f6\\uc9c0 \\uc54a\\uc544.\\n#Person2#: \\uadf8\\uac74 \\uc774\\ud574\\ud574. \\ud558\\uc9c0\\ub9cc \\uacc4\\uc18d\\ud574\\uc11c \\uae0d\\uc815\\uc801\\uc778 \\uba74\\uc5d0 \\uc9d1\\uc911\\ud558\\uc790. \\uadf8 \\ud30c\\ud2f0\\uac00 \\uae30\\ub2e4\\ub824\\uc9c0\\ub124.\",\n          \"#Person1#: \\uc2e4\\ub840\\ud569\\ub2c8\\ub2e4, \\uc568\\ub9ac\\uc2a4. \\uc774\\uacf3\\uc744 \\uc0ac\\uc6a9\\ud574\\ubcf8 \\uc801\\uc774 \\uc5c6\\ub294\\ub370, \\uae30\\uacc4\\ub97c \\uc5b4\\ub5bb\\uac8c \\uc0ac\\uc6a9\\ud558\\ub294\\uc9c0 \\uc54c\\ub824\\uc8fc\\uc2e4 \\uc218 \\uc788\\ub098\\uc694?\\r\\n#Person2#: \\uc5b4\\ub5a4 \\ub9d0\\uc500\\uc774\\uc2e0\\uac00\\uc694? \\uc774\\uac83\\ub4e4\\uc740 \\uc138\\ud0c1\\uae30\\uc785\\ub2c8\\ub2e4. \\uc800\\uae30 \\ud070 \\uac83\\ub4e4\\uc740 \\uac74\\uc870\\uae30\\uc785\\ub2c8\\ub2e4.\\r\\n#Person1#: \\uc54c\\uaca0\\uc2b5\\ub2c8\\ub2e4. \\uae30\\uacc4 \\uc548\\uc5d0 \\ube44\\ub204\\uac00 \\uc788\\ub098\\uc694?\\r\\n#Person2#: \\uc544\\ub2c8\\uc694, \\ub2f9\\uc5f0\\ud788 \\uc5c6\\uc2b5\\ub2c8\\ub2e4. \\ube44\\ub204\\ub97c \\ub123\\uc5b4\\uc57c \\ud569\\ub2c8\\ub2e4. \\ube44\\ub204\\ub97c \\uac00\\uc838\\uc624\\uc168\\ub098\\uc694?\\r\\n#Person1#: \\uc544\\ub2c8\\uc694, \\ube44\\ub204\\uac00 \\uc5c6\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person2#: \\uadf8\\ub7fc, \\uc800\\uae30\\uc11c \\uc0ac\\uc2e4 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person1#: \\uac10\\uc0ac\\ud569\\ub2c8\\ub2e4. \\ube44\\ub204\\ub97c \\uc0c0\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person2#: \\uc774\\ub7f0, \\uc815\\ub9d0 \\ub9ce\\uc774 \\uc0ac\\uc168\\ub124\\uc694. \\uc65c \\uc774\\ub807\\uac8c \\ub9ce\\uc774 \\ud544\\uc694\\ud55c\\uac00\\uc694?\\r\\n#Person1#: \\uc798 \\ubaa8\\ub974\\uaca0\\uc2b5\\ub2c8\\ub2e4. \\uc637\\uc744 \\uae68\\ub057\\ud558\\uac8c \\ud558\\uace0 \\uc2f6\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person2#: \\ud558\\uc9c0\\ub9cc \\uc774\\ub807\\uac8c \\ub9ce\\uc774 \\uc0ac\\uc6a9\\ud558\\uba74 \\uc548 \\ub429\\ub2c8\\ub2e4. \\uae30\\uacc4\\uac00 \\ube44\\ub204\\ub97c \\uc644\\uc804\\ud788 \\uc81c\\uac70\\ud558\\uc9c0 \\ubabb\\ud569\\ub2c8\\ub2e4. \\uc624\\ud788\\ub824 \\ub108\\ubb34 \\ub9ce\\uc740 \\uac70\\ud488\\uc774 \\uba3c\\uc9c0\\ub97c \\uac00\\ub46c\\uc11c, \\uc138\\uade0\\uc774 \\uc313\\uc774\\uac8c \\ub429\\ub2c8\\ub2e4.\\r\\n#Person1#: \\uc544, \\uadf8\\ub807\\uad70\\uc694. \\ubab0\\ub790\\uc2b5\\ub2c8\\ub2e4. \\uc800\\ub294 \\uc637\\uc744 \\ube68\\uc544\\ubcf8 \\uc801\\uc774 \\uc5c6\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person2#: \\ubb50\\uc694? \\uc637\\uc744 \\ube68\\uc544\\ubcf8 \\uc801\\uc774 \\uc5c6\\ub2e4\\uace0\\uc694?\\r\\n#Person1#: \\ub124, \\ud55c \\ubc88\\ub3c4 \\uc5c6\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person2#: \\ubbff\\uc744 \\uc218 \\uc5c6\\ub124\\uc694. \\uc5b4\\ub5bb\\uac8c \\uadf8\\ub7f4 \\uc218 \\uc788\\ub098\\uc694?\\r\\n#Person1#: \\uc81c \\uc5c4\\ub9c8\\uac00 \\ud56d\\uc0c1 \\ud574\\uc8fc\\uc168\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person2#: \\ub124, \\uc81c \\uc5c4\\ub9c8\\ub3c4 \\uc81c \\uc637\\uc744 \\ube68\\uc544\\uc8fc\\uc168\\uc2b5\\ub2c8\\ub2e4. \\ud558\\uc9c0\\ub9cc 12\\uc0b4 \\ub54c\\ubd80\\ud130 \\uc81c\\uac00 \\uc9c1\\uc811 \\uc637\\uc744 \\ube68\\uae30 \\uc2dc\\uc791\\ud588\\uc2b5\\ub2c8\\ub2e4.\\r\\n#Person1#: \\uadf8 \\uc0ac\\uc2e4\\uc740 \\uc54c\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\ubbf8\\uad6d \\uc544\\uc774\\ub4e4\\uc740 \\ub354 \\ub3c5\\ub9bd\\uc801\\uc785\\ub2c8\\ub2e4. \\ud558\\uc9c0\\ub9cc \\uc81c \\ub098\\ub77c\\uc5d0\\uc11c\\ub294 \\uc5c4\\ub9c8\\uac00 \\uc544\\uc774\\ub4e4\\uc774 \\ud559\\uad50\\uc5d0\\uc11c \\uc88b\\uc740 \\uc131\\uc801\\uc744 \\ubc1b\\uae30\\ub97c \\uc6d0\\ud558\\uae30 \\ub54c\\ubb38\\uc5d0, \\ubaa8\\ub4e0 \\uac83\\uc744 \\uc544\\uc774\\ub4e4 \\ub300\\uc2e0 \\ud574\\uc90d\\ub2c8\\ub2e4.\\r\\n#Person2#: \\uadf8\\ub807\\ub2e4\\uba74 \\ucea0\\ud37c\\uc2a4\\uc5d0\\uc11c \\uc5b4\\ub5bb\\uac8c \\uc0b4\\uc544\\uac08 \\uac74\\uac00\\uc694?\\r\\n#Person1#: \\uc798 \\ubaa8\\ub974\\uaca0\\uc2b5\\ub2c8\\ub2e4. \\ud798\\ub4e4\\uc9c0\\ub9cc \\ubc30\\uc6cc\\uc57c \\ud569\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}],"source":["# validation data의 구조와 내용을 확인합니다.\n","test_df = pd.read_csv(os.path.join(data_path,'test.csv'))\n","test_df.tail()"]},{"cell_type":"markdown","metadata":{"id":"RSbDC2PouU7A"},"source":["## 1. 모델 트레이닝"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4ilJw9PuU7A","executionInfo":{"status":"ok","timestamp":1725960164606,"user_tz":-540,"elapsed":6,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"ede1537b-eeac-4ab0-a903-943b21d4f57a"},"outputs":[{"output_type":"stream","name":"stdout","text":["---------- device : cuda:0 ----------\n","2.4.0+cu121\n"]}],"source":["# 사용할 device를 정의합니다. GPU가 사용 가능하면 'cuda:0', 그렇지 않으면 'cpu'를 사용합니다.\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print('-' * 10, f'device : {device}', '-' * 10,)\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"QuQkMMnouU7A"},"source":["### 1) 토크나이저와 모델 로드"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"rrv5IrRxuU7A","executionInfo":{"status":"ok","timestamp":1725960164606,"user_tz":-540,"elapsed":5,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["def load_tokenizer_and_model_for_train(config, device):\n","    print('-' * 10, 'Load tokenizer & model', '-' * 10,)\n","    print('-' * 10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-' * 10,)\n","\n","     #모델 이름 불러오기:\n","    # config['general']['model_name']을 통해 사전 학습된 모델의 이름을 설정 파일에서 불러옵니다.\n","    # 이는 Hugging Face의 모델 허브에서 가져올 모델의 이름입니다.\n","    model_name = config['general']['model_name']\n","\n","\n","    ### BART ##################\n","    # BART 설정 로드:\n","    # BartConfig를 사용하여 지정된 모델 이름으로부터 BART의 설정을 불러옵니다.\n","    # 이 설정은 모델의 구조와 하이퍼파라미터를 정의합니다.\n","    bart_config = BartConfig().from_pretrained(model_name)\n","\n","    # 토크나이저 로드:\n","    # AutoTokenizer.from_pretrained를 사용하여 지정된 모델 이름으로부터 토크나이저를 불러옵니다.\n","    # 이 토크나이저는 텍스트 데이터를 토큰화하는 역할을 합니다.\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    # 사전 학습된 모델 로드:\n","    # BartForConditionalGeneration.from_pretrained를 사용하여 사전 학습된 BART 모델을 불러옵니다.\n","    # 이 모델은 텍스트 생성, 요약 등의 작업을 수행하는 데 사용됩니다.\n","    generate_model = BartForConditionalGeneration.from_pretrained(model_name, config=bart_config)\n","\n","\n","    # 특수 토큰 추가:\n","    # special_tokens_dict를 사용하여 설정에서 정의한 특수 토큰을 토크나이저에 추가합니다.\n","    # 이는 예를 들어, 특정 인물이나 장소를 나타내는 토큰을 추가하는 등의 작업에 사용됩니다.\n","    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n","    tokenizer.add_special_tokens(special_tokens_dict)\n","    # 토크나이저에 추가된 토큰에 맞추어 모델의 토큰 임베딩 크기를 조정합니다.\n","    # 모델의 토큰 임베딩 크기를 업데이트된 토크나이저의 크기에 맞게 조정합니다.\n","    generate_model.resize_token_embeddings(len(tokenizer))\n","\n","\n","    # 모델을 지정된 디바이스로 이동:\n","    # 모델을 device 변수에 지정된 디바이스(GPU 또는 CPU)로 이동시킵니다.\n","    # 이를 통해 모델이 올바른 디바이스에서 실행되도록 합니다.\n","    generate_model.to(device)\n","\n","\n","    # 모델 설정 출력:\n","    # 로드된 모델의 설정을 출력하여, 모델의 구조와 하이퍼파라미터 등을 확인할 수 있습니다.\n","    print(generate_model.config)\n","\n","    print('-' * 10, 'Load tokenizer & model complete', '-' * 10,)\n","\n","    # 모델과 토크나이저 반환:\n","    return generate_model, tokenizer\n","\n","    # 최종적으로 불러온 모델과 토크나이저를 반환하여, 이후 학습 과정에서 사용할 수 있도록 준비합니다.\n","    # 이 함수는 학습을 위해 필요한 모델과 토크나이저를 설정 파일에 따라 자동으로 불러오고 준비해 줍니다.\n","    # 특수 토큰의 추가 및 모델 임베딩의 재구성도 함께 처리하여, 모델이 주어진 작업에 최적화될 수 있도록 돕습니다.\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d0cb595dc9ac4896b85ada713ddf49f3","fdfe08aec75949fb95d4cebe10b1ec17","a7be9039bcfe497c97888d5bfdfd231a","9eb6d93455b440e99bb1ff07f76e1c3d","8ceb9e746e0341ae81f7a11a96401566","ec7f93ca4ea9453892cb5a6c9699433c","df0cb538f20d46c7be0f38ae49bcdf96","464f872db2a54d6081f504183735a922","e717bb64d5134494a2cd93c9a563a51c","13639687c93b4c8393f48b2f942818f3","ece27f48627b4fb4aa9b79a1271d632d","e4d4c97959a94325af0c23e68ce9618b","9d21add2963948b085f3dc949d169f2e","30b4b353d77b42b78c270f86c4788231","0d8108a9a901427fa833374190694bb0","92886a84d19741f0941dbc4dc8a68fb4","9e78cd0aa3f249e6b98f6186bee68e4f","5a3c3382e4d5436796af47505ddada9b","bd5cd53d9a094b408c27c343bc4ac8e8","9e216987afb24a1aa40dd7b28141763f","e9b5cae3283042a6babf46045195e5ed","54a7636c0ac445019752e4cf3f2c4a19"]},"id":"Ywi-fJj0uU7A","executionInfo":{"status":"ok","timestamp":1725960172423,"user_tz":-540,"elapsed":7822,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"3fd7310b-2499-4135-c040-8a43e4f1f1e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######  사용할 모델과 토크나이저를 로드합니다.  ################################################################################\n","---------- Load tokenizer & model ----------\n","---------- Model Name : jx7789/kobart_summary_v3 ----------\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.82k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0cb595dc9ac4896b85ada713ddf49f3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d4c97959a94325af0c23e68ce9618b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["BartConfig {\n","  \"_name_or_path\": \"jx7789/kobart_summary_v3\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 1,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.1,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 1,\n","  \"do_blenderbot_90_layernorm\": false,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"NEGATIVE\",\n","    \"1\": \"POSITIVE\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"kobart_version\": 2.0,\n","  \"label2id\": {\n","    \"NEGATIVE\": 0,\n","    \"POSITIVE\": 1\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 64,\n","  \"max_position_embeddings\": 1026,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 3,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 30046\n","}\n","\n","---------- Load tokenizer & model complete ----------\n","---------- tokenizer special tokens :  {'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#SSN#', '#PhoneNumber#', '#Address#', '#Email#', '#CarNumber#', '#CardNumber##DateOfBirth#', '#PassportNumber#']} ----------\n"]}],"source":["# 사용할 모델과 토크나이저를 로드합니다.\n","print(\"\\n#######  사용할 모델과 토크나이저를 로드합니다.  ################################################################################\")\n","generate_model, tokenizer = load_tokenizer_and_model_for_train(config, device)\n","print('-' * 10, \"tokenizer special tokens : \", tokenizer.special_tokens_map, '-' * 10)"]},{"cell_type":"markdown","metadata":{"id":"BeElc0xxuU7A"},"source":["### 2) 전처리"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"tH3PUGYeuU7A","executionInfo":{"status":"ok","timestamp":1725960172423,"user_tz":-540,"elapsed":7,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["\n","# 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n","class Preprocess:\n","    def __init__(self,\n","            bos_token: str,\n","            eos_token: str,\n","        ) -> None:\n","\n","        # 클래스 초기화 메서드입니다. 시작 토큰(bos_token)과 종료 토큰(eos_token)을 인스턴스 변수로 저장합니다.\n","        self.bos_token = bos_token\n","        self.eos_token = eos_token\n","\n","    @staticmethod\n","    # 파일 경로를 입력 받아 CSV 파일을 읽고, 필요한 컬럼들만 선택하여 데이터프레임으로 반환합니다.\n","    def make_set_as_df(file_path, is_train = True):\n","\n","        # is_train이 True면 학습용 데이터로, False면 테스트용 데이터로 처리합니다.\n","        if is_train:\n","            df = pd.read_csv(file_path)\n","            train_df = df[['fname','dialogue','summary']]\n","            return train_df\n","\n","        # 테스트 데이터인 경우, 'fname'과 'dialogue' 컬럼만 선택하여 반환합니다.\n","        else:\n","            df = pd.read_csv(file_path)\n","            test_df = df[['fname','dialogue']]\n","            return test_df\n","\n","\n","    # BART 모델의 입력과 출력을 생성하는 메서드입니다.\n","    def make_input(self, dataset, is_test=False):\n","\n","        # is_test가 True면 테스트 데이터를 위한 입력만 생성하고, False면 학습 데이터를 위한 입력과 출력을 생성합니다.\n","        if is_test:\n","            # 테스트 데이터의 경우, 인코더 입력과 디코더의 시작 토큰으로만 구성된 입력을 반환합니다.\n","            # 인코더 입력으로 'dialogue' 텍스트를 사용합니다.\n","            encoder_input = dataset['dialogue']\n","            # 디코더 입력은 시작 토큰으로만 구성합니다.\n","            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n","\n","            return encoder_input.tolist(), list(decoder_input)\n","        else:\n","            # 학습 데이터의 경우, 인코더 입력, 디코더 입력, 디코더 출력을 모두 생성합니다.\n","            encoder_input = dataset['dialogue']  # 인코더 입력으로 'dialogue' 텍스트를 사용합니다.\n","\n","            # 디코더 입력은 시작 토큰(bos_token)과 요약 텍스트(summary)로 구성됩니다.\n","            decoder_input = dataset['summary'].apply(lambda x: self.bos_token + str(x))\n","\n","            # 디코더 출력은 요약 텍스트(summary)와 종료 토큰(eos_token)으로 구성됩니다.\n","            decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n","\n","            # 리스트로 변환하여 반환합니다.\n","            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mv0ALffOuU7B","executionInfo":{"status":"ok","timestamp":1725960172424,"user_tz":-540,"elapsed":8,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"a2f876cd-a904-4631-ae12-3d89d43ee62b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######  학습에 사용할 데이터셋을 전처리하고 로드합니다.  ########################################################################\n"]}],"source":["# 학습에 사용할 데이터셋을 전처리하고 로드합니다.\n","print(\"\\n#######  학습에 사용할 데이터셋을 전처리하고 로드합니다.  ########################################################################\")\n","# 시작 토큰(beginning of sentence)과 종료 토큰(end of sentence)을 설정합니다.\n","preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n"]},{"cell_type":"markdown","metadata":{"id":"QGg8MTqsuU7B"},"source":["### 3) 학습 및 검증 데이터셋 준비"]},{"cell_type":"markdown","metadata":{"id":"snIYLPVzuU7B"},"source":["#### 3-1) Train, Validation, Test 클래스 정의"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"dA-6hiOduU7B","executionInfo":{"status":"ok","timestamp":1725960172424,"user_tz":-540,"elapsed":7,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["# Train에 사용되는 Dataset 클래스를 정의합니다.\n","class DatasetForTrain(Dataset):\n","    def __init__(self, encoder_input, decoder_input, labels, len):\n","        # 학습 데이터셋 초기화 메서드입니다. 인코더 입력, 디코더 입력, 레이블, 데이터 길이를 저장합니다.\n","        self.encoder_input = encoder_input\n","        self.decoder_input = decoder_input\n","        self.labels = labels\n","        self.len = len\n","\n","    def __getitem__(self, idx):\n","        # 주어진 인덱스(idx)에 해당하는 데이터를 반환하는 메서드입니다.\n","\n","        # 인코더 입력 데이터에서 해당 인덱스의 데이터를 복사하여 `item` 딕셔너리에 저장합니다.\n","        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}  # item[input_ids], item[attention_mask]\n","\n","        # 디코더 입력 데이터에서 해당 인덱스의 데이터를 복사하여 `item2` 딕셔너리에 저장합니다.\n","        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}  # item2[input_ids], item2[attention_mask]\n","\n","        # `item2` 딕셔너리의 'input_ids'와 'attention_mask'를 각각 'decoder_input_ids'와 'decoder_attention_mask'로 이름을 변경합니다.\n","        item2['decoder_input_ids'] = item2['input_ids']\n","        item2['decoder_attention_mask'] = item2['attention_mask']\n","        item2.pop('input_ids')  # 'input_ids' 키 제거\n","        item2.pop('attention_mask')  # 'attention_mask' 키 제거\n","\n","        # `item` 딕셔너리에 디코더의 입력 정보를 추가합니다.\n","        item.update(item2)  # item[input_ids], item[attention_mask], item[decoder_input_ids], item[decoder_attention_mask]\n","\n","        # 레이블로 사용할 'input_ids' 값을 `item` 딕셔너리에 추가합니다.\n","        item['labels'] = self.labels['input_ids'][idx]  # item[input_ids], item[attention_mask], item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n","\n","        return item\n","\n","    def __len__(self):\n","        # 데이터셋의 길이를 반환하는 메서드입니다.\n","        return self.len\n","\n","\n","# Validation에 사용되는 Dataset 클래스를 정의합니다.\n","class DatasetForVal(Dataset):\n","    def __init__(self, encoder_input, decoder_input, labels, len):\n","        # 검증 데이터셋 초기화 메서드입니다. 학습 데이터셋과 동일한 구조로 정의됩니다.\n","        self.encoder_input = encoder_input\n","        self.decoder_input = decoder_input\n","        self.labels = labels\n","        self.len = len\n","\n","    def __getitem__(self, idx):\n","        # 주어진 인덱스(idx)에 해당하는 데이터를 반환하는 메서드입니다.\n","        # 학습 데이터셋과 동일하게 정의됩니다.\n","        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n","        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n","        item2['decoder_input_ids'] = item2['input_ids']\n","        item2['decoder_attention_mask'] = item2['attention_mask']\n","        item2.pop('input_ids')\n","        item2.pop('attention_mask')\n","        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n","        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n","        return item\n","\n","    def __len__(self):\n","        # 데이터셋의 길이를 반환하는 메서드입니다.\n","        return self.len\n","\n","\n","# Test에 사용되는 Dataset 클래스를 정의합니다.\n","class DatasetForInference(Dataset):     # inference뜻 : 추론\n","    def __init__(self, encoder_input, test_id, len):\n","        # 테스트 데이터셋 초기화 메서드입니다. 인코더 입력, 테스트 ID, 데이터 길이를 저장합니다.\n","        self.encoder_input = encoder_input\n","        self.test_id = test_id\n","        self.len = len\n","\n","    def __getitem__(self, idx):\n","        # 주어진 인덱스(idx)에 해당하는 데이터를 반환하는 메서드입니다.\n","        # 인코더 입력 데이터에서 해당 인덱스의 데이터를 복사하여 `item` 딕셔너리에 저장합니다.\n","        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n","        item['ID'] = self.test_id[idx]\n","        return item\n","\n","    def __len__(self):\n","        # 데이터셋의 길이를 반환하는 메서드입니다.\n","        return self.len\n"]},{"cell_type":"markdown","metadata":{"id":"j1TNfNoouU7B"},"source":["#### 3-2) Train, Validation 데이터셋 준비"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"a5sotZePuU7B","executionInfo":{"status":"ok","timestamp":1725960172424,"user_tz":-540,"elapsed":7,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n","\n","    ### 데이터 로드 및 변환:\n","    #학습 및 검증 데이터 파일을 읽어 데이터프레임으로 변환합니다.\n","    #데이터프레임으로 변환된 데이터에서 대화(dialogue)와 요약(summary) 텍스트를 각각 학습 입력과 라벨로 사용합니다.\n","    # 데이터셋 경로를 지정합니다.\n","    train_file_path = os.path.join(data_path, train)  # 학습 데이터 파일 경로\n","    val_file_path = os.path.join(data_path, 'dev.csv')  # 검증 데이터 파일 경로\n","    # 학습(train)과 검증(validation) 데이터셋을 데이터프레임으로 변환합니다.\n","    train_data = preprocessor.make_set_as_df(train_file_path)  # 학습 데이터 로드\n","    val_data = preprocessor.make_set_as_df(val_file_path)  # 검증 데이터 로드\n","    # 로드된 학습 데이터와 라벨의 첫 번째 샘플을 출력합니다.\n","    print('-' * 150)\n","    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n","    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n","    # 로드된 검증 데이터와 라벨의 첫 번째 샘플을 출력합니다.\n","    print('-' * 150)\n","    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n","    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n","\n","\n","    ### 데이터 전처리:\n","    # Preprocess 클래스의 make_input 메서드를 사용하여 인코더 입력, 디코더 입력, 디코더 출력을 생성합니다.\n","    # 이 과정에서 BART 모델에 적합한 형태로 텍스트 데이터를 구성합니다.\n","    # 학습 데이터에 대해 인코더 입력, 디코더 입력, 디코더 출력을 생성합니다.\n","    encoder_input_train, decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n","    # 검증 데이터에 대해 인코더 입력, 디코더 입력, 디코더 출력을 생성합니다.\n","    encoder_input_val, decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n","    print('-' * 10, 'Load data complete', '-' * 10)\n","\n","\n","    ### 토큰화:\n","    # 텍스트 데이터를 tokenizer를 사용하여 토큰화합니다. 토큰화 과정에서:\n","    # 텍스트를 토큰 ID로 변환합니다.\n","    # 필요한 경우, 패딩(padding=True), 최대 길이(max_length), 특수 토큰(add_special_tokens=True) 등을 추가합니다.\n","    # 반환된 데이터는 PyTorch 텐서(return_tensors=\"pt\")로 반환됩니다.\n","    # 학습 데이터의 인코더 입력을 토크나이저로 토큰화합니다.\n","    tokenized_encoder_inputs = tokenizer(\n","        encoder_input_train, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False\n","    )\n","    # 학습 데이터의 디코더 입력을 토크나이저로 토큰화합니다.\n","    tokenized_decoder_inputs = tokenizer(\n","        decoder_input_train, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False\n","    )\n","    # 학습 데이터의 디코더 출력을 토크나이저로 토큰화합니다.\n","    tokenized_decoder_ouputs = tokenizer(\n","        decoder_output_train, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False\n","    )\n","\n","\n","    ### 데이터셋 생성:\n","    # 학습 데이터와 검증 데이터를 각각 DatasetForTrain과 DatasetForVal 클래스로 감싸 데이터셋 객체를 생성합니다.\n","    # 이 객체들은 PyTorch의 DataLoader와 함께 사용되어 모델 학습 및 검증에 활용됩니다.\n","    # 학습용 데이터셋을 생성합니다.\n","    train_inputs_dataset = DatasetForTrain(\n","        tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs, len(encoder_input_train)\n","    )\n","    # 검증 데이터의 인코더 입력을 토크나이저로 토큰화합니다.\n","    val_tokenized_encoder_inputs = tokenizer(\n","        encoder_input_val, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False\n","    )\n","    # 검증 데이터의 디코더 입력을 토크나이저로 토큰화합니다.\n","    val_tokenized_decoder_inputs = tokenizer(\n","        decoder_input_val, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False\n","    )\n","    # 검증 데이터의 디코더 출력을 토크나이저로 토큰화합니다.\n","    val_tokenized_decoder_ouputs = tokenizer(\n","        decoder_output_val, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False\n","    )\n","    # 검증용 데이터셋을 생성합니다.\n","    val_inputs_dataset = DatasetForVal(\n","        val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs, len(encoder_input_val)\n","    )\n","    print('-' * 10, 'Make dataset complete', '-' * 10)\n","\n","\n","    ### 출력 및 반환:\n","    # 학습용 데이터셋과 검증용 데이터셋을 반환합니다. 이를 통해 모델 학습 과정에서 필요한 데이터를 제공하게 됩니다.\n","    return train_inputs_dataset, val_inputs_dataset\n","\n","\n","    # 이 함수는 모델 학습 및 검증을 위한 데이터 준비 과정에서 필요한\n","    # 모든 전처리, 토큰화, 데이터셋 생성을 자동으로 처리하여, 최종적으로 Dataset 객체를 반환합니다.\n","    # 이를 통해 모델 학습 및 검증을 효율적으로 수행할 수 있습니다.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wixy26OjuU7C","outputId":"76b32c41-7e0e-4cb4-99b9-ee6e733b09c9","executionInfo":{"status":"ok","timestamp":1725960187258,"user_tz":-540,"elapsed":14840,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######  학습 및 검증 데이터셋을 준비합니다.  ###################################################################################\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","train_data:\n"," #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n","#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n","#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n","#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n","#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n","#Person2#: 알겠습니다.\n","#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n","#Person2#: 네.\n","#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n","#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n","#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n","#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n","train_label:\n"," 스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","val_data:\n"," #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n","#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n","#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n","#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n","#Person1#: 알고 있는 알레르기가 있나요?\n","#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n","#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n","#Person2#: 운동을 할 때 많이 나타나요.\n","#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n","#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n","val_label:\n"," #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다. \n","---------- Load data complete ----------\n","---------- Make dataset complete ----------\n"]}],"source":["print(\"\\n#######  학습 및 검증 데이터셋을 준비합니다.  ###################################################################################\")\n","# 학습 및 검증 데이터셋을 준비합니다.\n","data_path = config['general']['data_path']  # 데이터 경로를 설정에서 가져옵니다.\n","train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config, preprocessor, data_path, tokenizer)\n"]},{"cell_type":"markdown","metadata":{"id":"A2bzm0nruU7C"},"source":["### 4) Trainer 클래스 초기화"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"esz4VT63uU7C","executionInfo":{"status":"ok","timestamp":1725960187258,"user_tz":-540,"elapsed":9,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["def compute_metrics(config, tokenizer, pred):\n","    ### rouge = Rouge():\n","    # ROUGE 점수를 계산하기 위해 Rouge 클래스를 초기화합니다.\n","    # ROUGE는 주로 텍스트 요약의 품질을 평가할 때 사용되는 지표입니다.\n","    rouge = Rouge()\n","\n","\n","    ### pred.predictions 및 pred.label_ids:\n","    # predictions: 모델이 예측한 토큰 ID의 배열입니다.\n","    # label_ids: 실제 레이블(정답) 토큰 ID의 배열입니다.\n","    # 예측된 토큰 ID와 실제 레이블 ID를 가져옵니다.\n","    predictions = pred.predictions\n","    labels = pred.label_ids\n","\n","\n","    ### 패딩 토큰 처리:\n","    # 예측 값과 레이블에서 -100으로 표시된 패딩 토큰을 실제 패딩 토큰 ID로 교체하여 평가에서 패딩이 영향을 미치지 않도록 합니다.\n","    # 모델 출력 중 패딩 토큰을 의미하는 -100 값을 tokenizer의 패딩 토큰 ID로 변경합니다.\n","    predictions[predictions == -100] = tokenizer.pad_token_id\n","    labels[labels == -100] = tokenizer.pad_token_id\n","\n","\n","    ### 토큰 디코딩:\n","    # 토큰 ID 배열을 원래의 텍스트 문자열로 변환합니다.\n","    # batch_decode는 여러 개의 토큰 배열을 한꺼번에 디코딩합니다.\n","    # 예측된 토큰 ID를 텍스트로 디코딩합니다.\n","    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n","    # 실제 레이블의 토큰 ID도 텍스트로 디코딩합니다.\n","    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n","\n","\n","    ### 불필요한 토큰 제거:\n","    # 모델이 생성한 텍스트에서 사전에 정의된 불필요한 토큰을 제거하여 평가의 정확성을 높입니다.\n","    # 평가를 위해 불필요한 토큰들을 제거합니다.\n","    replaced_predictions = decoded_preds.copy()  # 예측된 텍스트 복사\n","    replaced_labels = labels.copy()  # 실제 레이블 텍스트 복사\n","    remove_tokens = config['inference']['remove_tokens']  # 제거할 토큰 목록을 config에서 가져옵니다.\n","    # 각 불필요한 토큰을 제거합니다.\n","    for token in remove_tokens:\n","        replaced_predictions = [sentence.replace(token, \" \") for sentence in replaced_predictions]\n","        replaced_labels = [sentence.replace(token, \" \") for sentence in replaced_labels]\n","\n","\n","    ### 출력:\n","    # 평가를 위해 디코딩된 예측 텍스트와 실제 레이블의 일부 샘플을 출력합니다.\n","    # 첫 번째, 두 번째, 세 번째 예측과 실제 레이블을 출력합니다.\n","    print('-' * 150)\n","    print(f\"PRED: {replaced_predictions[0]}\")\n","    print(f\"GOLD: {replaced_labels[0]}\")\n","    print('-' * 150)\n","    print(f\"PRED: {replaced_predictions[1]}\")\n","    print(f\"GOLD: {replaced_labels[1]}\")\n","    print('-' * 150)\n","    print(f\"PRED: {replaced_predictions[2]}\")\n","    print(f\"GOLD: {replaced_labels[2]}\")\n","\n","\n","    ### ROUGE 점수 계산:\n","    # replaced_predictions와 replaced_labels를 사용하여 ROUGE 점수를 계산합니다.\n","    # ROUGE-1, ROUGE-2, ROUGE-L 등의 F1 점수를 계산하여 반환합니다.\n","    # 최종적으로 ROUGE 점수를 계산합니다.\n","    results = rouge.get_scores(replaced_predictions, replaced_labels, avg=True)\n","\n","\n","    ### 결과 반환:\n","    # ROUGE 점수 중 F1-score를 추출하여 딕셔너리 형태로 반환합니다.\n","    result = {key: value[\"f\"] for key, value in results.items()}\n","    return result\n","\n","\n","    # 이 함수는 모델이 생성한 텍스트의 품질을 ROUGE 지표로 평가하여,\n","    # 모델 성능을 평가하는 데 중요한 역할을 합니다.\n","    # ROUGE 점수를 통해 텍스트 요약 또는 생성 모델의 정확성을 평가할 수 있습니다.\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"EHeARDkquU7C","executionInfo":{"status":"ok","timestamp":1725960187258,"user_tz":-540,"elapsed":9,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}}},"outputs":[],"source":["def load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset):\n","    print('-' * 10, 'Make training arguments', '-' * 10,)\n","\n","    ### Seq2SeqTrainingArguments 설정:\n","    # 학습과 관련된 다양한 설정값들을 정의하는 Seq2SeqTrainingArguments 객체를 생성합니다.\n","    # 학습률, 배치 크기, 에포크 수, 로그 저장 위치 등 다양한 하이퍼파라미터와 옵션들이 포함됩니다.\n","    # 학습을 위한 설정값들을 정의합니다.\n","    training_args = Seq2SeqTrainingArguments(\n","        output_dir=config['general']['output_dir'],                                     # 모델 출력 디렉터리\n","        overwrite_output_dir=config['training']['overwrite_output_dir'],                # 출력 디렉터리를 덮어쓸지 여부\n","        num_train_epochs=config['training']['num_train_epochs'],                        # 전체 학습 에포크 수\n","        learning_rate=config['training']['learning_rate'],                              # 학습률\n","        per_device_train_batch_size=config['training']['per_device_train_batch_size'],  # 학습 시 디바이스당 배치 크기\n","        per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],    # 평가 시 디바이스당 배치 크기\n","        warmup_ratio=config['training']['warmup_ratio'],                                # 학습 초기에 학습률을 점진적으로 증가시키는 비율\n","        weight_decay=config['training']['weight_decay'],                                # 가중치 감쇠 (과적합 방지)\n","        lr_scheduler_type=config['training']['lr_scheduler_type'],                      # 학습률 스케줄러 유형\n","        optim=config['training']['optim'],                                              # 옵티마이저 종류\n","        gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],  # 기울기(gradient) 축적 단계 수\n","        evaluation_strategy=config['training']['evaluation_strategy'],                  # 학습 중 평가 전략 (예: 에포크마다 평가)\n","        save_strategy=config['training']['save_strategy'],                              # 모델 저장 전략\n","        save_total_limit=config['training']['save_total_limit'],                        # 저장할 체크포인트의 최대 개수\n","        fp16=config['training']['fp16'],                                                # 반정밀도(float16) 연산 사용 여부\n","        load_best_model_at_end=config['training']['load_best_model_at_end'],            # 학습 종료 시 가장 좋은 모델 로드\n","        seed=config['training']['seed'],                                                # 랜덤 시드 설정\n","        logging_dir=config['training']['logging_dir'],                                  # 로그 저장 디렉터리\n","        logging_strategy=config['training']['logging_strategy'],                        # 로그 기록 전략 (예: 에포크마다 기록)\n","        predict_with_generate=config['training']['predict_with_generate'],              # 텍스트 생성 후 평가 지표를 계산할지 여부\n","        generation_max_length=config['training']['generation_max_length'],              # 텍스트 생성 시 최대 길이\n","        do_train=config['training']['do_train'],                                        # 학습 수행 여부\n","        do_eval=config['training']['do_eval'],                                          # 평가 수행 여부\n","        report_to=config['training']['report_to']                                       # (선택 사항) wandb로 학습 과정을 기록할지 여부\n","    )\n","\n","\n","    ### wandb 초기화 (선택 사항):\n","    # (선택 사항) wandb를 사용하여 학습 과정을 추적할 때 초기화합니다.\n","    # WandB(Weights & Biases)로 학습 과정을 추적하고 시각화하려면 wandb.init()을 사용해 초기화할 수 있습니다.\n","    # 이 부분은 현재 주석 처리되어 있으며, 필요한 경우 활성화할 수 있습니다.\n","    wandb.init(\n","         entity=config['wandb']['entity'],\n","         project=config['wandb']['project'],\n","         name=config['wandb']['name']\n","    )\n","    # (선택 사항) 모델 체크포인트를 wandb에 저장하도록 환경 변수를 설정합니다.\n","    os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n","    os.environ[\"WANDB_WATCH\"] = \"false\"\n","\n","\n","    ### EarlyStoppingCallback 설정:\n","    # EarlyStoppingCallback을 사용하여 학습이 진행될 때 검증 손실이 더 이상 개선되지 않으면 학습을 조기에 중단시킵니다.\n","    # 설정된 early_stopping_patience와 early_stopping_threshold에 따라 작동합니다.\n","    # EarlyStoppingCallback: 검증 손실이 더 이상 개선되지 않을 때 학습을 중단시키는 콜백을 설정합니다.\n","    MyCallback = EarlyStoppingCallback(\n","        early_stopping_patience=config['training']['early_stopping_patience'],      # 개선이 없을 경우 중단까지 기다릴 에포크 수\n","        early_stopping_threshold=config['training']['early_stopping_threshold']     # 개선으로 간주할 최소 손실 감소량\n","    )\n","    print('-' * 10, 'Make training arguments complete', '-' * 10,)\n","    print('-' * 10, 'Make trainer', '-' * 10,)\n","\n","\n","    ### Seq2SeqTrainer 초기화:\n","    # Seq2SeqTrainer는 Hugging Face의 transformers 라이브러리에서 제공하는 훈련 도구로,\n","    # 시퀀스-투-시퀀스 모델의 학습과 평가를 위한 도구입니다.\n","    # 학습할 모델, 설정값, 학습/검증 데이터셋, 평가 메트릭 함수, 콜백 등을 인자로 받아 초기화합니다.\n","    trainer = Seq2SeqTrainer(\n","        model=generate_model,  # 학습할 모델\n","        args=training_args,  # 학습 설정값\n","        train_dataset=train_inputs_dataset,  # 학습 데이터셋\n","        eval_dataset=val_inputs_dataset,  # 검증 데이터셋\n","        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),  # 성능 평가를 위한 메트릭 함수\n","        callbacks=[MyCallback]  # EarlyStoppingCallback을 포함한 콜백 리스트\n","    )\n","    print('-' * 10, 'Make trainer complete', '-' * 10,)\n","\n","    ### Trainer 객체 반환:\n","    # 생성된 trainer 객체를 반환하여, 이후 학습을 진행할 수 있게 합니다.\n","    return trainer\n","\n","\n","    # 이 함수는 모델 학습을 시작하기 위한 모든 준비 작업을 자동으로 처리하며,\n","    # 사용자에게 최적화된 Trainer 객체를 제공합니다. 이를 통해 학습 및 평가를 손쉽게 수행할 수 있습니다.\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"-uYBpr8AuU7C","colab":{"base_uri":"https://localhost:8080/","height":327},"executionInfo":{"status":"ok","timestamp":1725960191189,"user_tz":-540,"elapsed":3939,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"}},"outputId":"90f510cd-0b2c-4f14-ac1d-2caf5ffe8b50"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkukky\u001b[0m (\u001b[33mkkukky-empty\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"stream","name":"stdout","text":["\n","#######  학습을 위한 Trainer 클래스를 초기화합니다.  ############################################################################\n","---------- Make training arguments ----------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.17.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240910_092307-qs27niuy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/kkukky-empty/NLP2/runs/qs27niuy' target=\"_blank\">jx7789_kobart_summary_v3-bat16-5l6-n4-b5</a></strong> to <a href='https://wandb.ai/kkukky-empty/NLP2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/kkukky-empty/NLP2' target=\"_blank\">https://wandb.ai/kkukky-empty/NLP2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/kkukky-empty/NLP2/runs/qs27niuy' target=\"_blank\">https://wandb.ai/kkukky-empty/NLP2/runs/qs27niuy</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["---------- Make training arguments complete ----------\n","---------- Make trainer ----------\n","---------- Make trainer complete ----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]}],"source":["print(\"\\n#######  학습을 위한 Trainer 클래스를 초기화합니다.  ############################################################################\")\n","# 학습을 위한 Trainer 클래스를 초기화합니다.\n","trainer = load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset)"]},{"cell_type":"markdown","metadata":{"id":"6FnbXnrZuU7D"},"source":["### 5) 모델 학습, wandb 세션종료"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wmOw41HuU7D","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"333e301c-0572-4e52-e773-aa81413ede81"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######  모델 학습을 시작합니다.  ##############################################################################################\n","jx7789_kobart_summary_v3-bat16-5l6-n4-b5\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3190' max='7800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3190/7800 1:21:52 < 1:58:23, 0.65 it/s, Epoch 8.18/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge-1</th>\n","      <th>Rouge-2</th>\n","      <th>Rouge-l</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>6.806100</td>\n","      <td>2.874519</td>\n","      <td>0.179094</td>\n","      <td>0.036713</td>\n","      <td>0.174133</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.364000</td>\n","      <td>0.668108</td>\n","      <td>0.342405</td>\n","      <td>0.124773</td>\n","      <td>0.330418</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.363800</td>\n","      <td>0.578482</td>\n","      <td>0.365333</td>\n","      <td>0.141212</td>\n","      <td>0.352685</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.326800</td>\n","      <td>0.563477</td>\n","      <td>0.375387</td>\n","      <td>0.141772</td>\n","      <td>0.360491</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.310900</td>\n","      <td>0.557052</td>\n","      <td>0.376269</td>\n","      <td>0.144840</td>\n","      <td>0.360450</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.299000</td>\n","      <td>0.551499</td>\n","      <td>0.373799</td>\n","      <td>0.143289</td>\n","      <td>0.360469</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.289100</td>\n","      <td>0.548380</td>\n","      <td>0.380743</td>\n","      <td>0.149457</td>\n","      <td>0.367155</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.280900</td>\n","      <td>0.547336</td>\n","      <td>0.378506</td>\n","      <td>0.147188</td>\n","      <td>0.363700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:   감기 때문에 숨을 쉴 때마다 가슴이 무겁다고 하자 알고 있는 알레르기는 없다고 한다.                                             \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:   3시 30분에 헬스장에서 만나서 다리와 팔, 팔을 운동하자고 제안한다.                                              \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:   더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말하면서 어떤 음식을 먹고 있는지에 대해 이야기한다.                                          \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-390)... Done. 15.4s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 #Person1# 에게 감기 같은 알레르기가 있는지 물어봅니다. #Person1# 은 #Person2# 에게 천식에 대한 검사를 받게 할 것입니다.                                            \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 지미에게 운동하러 가자고 제안하고, 지미는 #Person1# 에게 3시 30분에 헬스장에서 만나자고 제안한다.                                               \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추고 과일, 채소, 닭고기를 먹는다. #Person1# 은 닭고기는 건강에 좋다고 생각한다.                                             \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-780)... Done. 14.7s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 숨을 쉴 때마다 가슴이 무겁다고 #Person1# 에게 말합니다. #Person1# 은 #Person2# 에게 천식에 대한 검사를 받게 할 것입니다.                                                                   \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:   지미는 #Person1# 에게 운동하러 가자고 제안한다. #Person1# 은 #Person2# 에게 헬스장에서 만나자고 제안하고, #Person2# 는 동의한다.                                                                 \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 #Person2# 에게 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말하고, #Person2# 는 주로 과일, 채소, 그리고 닭고기를 먹는다고 말한다.                                                               \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-1170)... Done. 9.7s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 숨을 쉴 때마다 가슴이 무겁다고 #Person1# 에게 말한다. #Person1# 은 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                                               \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:   지미는 #Person1# 에게 운동하러 가자고 제안한다. #Person1# 은 동의하고 헬스장에서 만나기로 한다.                                                                                          \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 과 #Person2# 는 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 생각한다. #Person1# 은 과일과 채소가 건강에 좋다고 생각한다.                                                                                      \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-1560)... Done. 15.0s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 #Person1# 에게 숨을 쉴 때마다 가슴이 무겁다고 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                                    \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 지미에게 운동하러 가자고 제안한다. 지미는 다리와 팔목을 운동하자고 제안한다. #Person1# 은 동의한다.                                                                                            \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추고 과일, 채소, 그리고 닭고기를 먹는다고 #Person2# 에게 말한다.                                                                                            \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-1950)... Done. 11.4s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 #Person1# 에게 숨쉬기가 힘들다고 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                                       \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 지미에게 운동하러 가자고 제안한다. 지미는 다리와 팔목을 운동하고 #Person1# 은 금요일에 다리를 할 수 있다.                                                                                           \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추고 과일, 채소, 그리고 닭고기를 먹는다. #Person2# 는 닭고기가 건강에 좋다고 생각한다.                                                                                         \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-2340)... Done. 10.5s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 #Person1# 에게 숨을 쉴 때마다 가슴이 무겁다고 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                      \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:   지미는 #Person1# 에게 운동하러 가자고 제안한다. #Person1# 은 지미에게 헬스장에서 만나자고 제안하고, 지미는 동의한다.                                                                           \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추고 과일, 채소, 그리고 닭고기를 먹는다고 #Person2# 에게 말한다.                                                                              \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-2730)... Done. 7.7s\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person2# 는 #Person1# 에게 숨을 쉴 때마다 가슴이 무겁다고 말합니다. #Person1# 는 #Person2# 를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것입니다.                                                                             \n","GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 지미에게 운동하러 가자고 제안하고, 지미는 동의한다. 그들은 금요일에 다리를 할 수 있다.                                                                                         \n","GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n","------------------------------------------------------------------------------------------------------------------------------------------------------\n","PRED:  #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추고 과일, 채소, 그리고 닭고기를 먹는다고 #Person2# 에게 말한다.                                                                                     \n","GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"]},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 5, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 1}\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./checkpoint-3120)... Done. 14.0s\n"]}],"source":["print(\"\\n#######  모델 학습을 시작합니다.  ##############################################################################################\")\n","print(title)\n","# 모델 학습을 시작합니다.\n","trainer.train()\n","\n","print(\"\\n#######  wandb 세션을 종료합니다.  ############################################################################################\")\n","# (선택) 모델 학습이 완료된 후 wandb 세션을 종료합니다.\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"1aNeSxAnuU7D"},"source":["## 2. 모델 추론하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xoppTq_4uU7D"},"outputs":[],"source":["# 이곳에 내가 사용할 wandb config 설정 \"추론에 사용할 ckt 경로 설정\"\n","# loaded_config['inference']['ckt_path'] = \"home/ckt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7yQbm0auU7D"},"outputs":[],"source":["# 사용할 device를 정의합니다. GPU가 사용 가능하면 'cuda:0', 그렇지 않으면 'cpu'를 사용합니다.\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print('-' * 10, f'device : {device}', '-' * 10,)\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"lOG8WafxuU7D"},"source":["### 1) 모델과 토크나이저 불러오기"]},{"cell_type":"markdown","metadata":{"id":"2KlKMdWNuU7D"},"source":["<font color=red size=32><b> ckt 값 바꾸기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxK3z-ZGuU7D"},"outputs":[],"source":["멈춤"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FERPc5NQuU7E"},"outputs":[],"source":["checkpoint_num = \"62290\"\n","\n","# 추론을 위한 tokenizer와 학습시킨 모델을 불러옵니다.\n","def load_tokenizer_and_model_for_test(config, device):\n","    print('-' * 10, 'Load tokenizer & model', '-' * 10,)\n","\n","    print(\"\\n######  설정 파일에서 모델 이름과 체크포인트 경로를 불러옵니다.\")\n","    ### 모델 이름과 체크포인트 경로 설정:\n","    # 설정 파일에서 모델 이름과 체크포인트 경로를 불러옵니다.\n","    # config['general']['model_name']: 사전 학습된 모델의 이름을 설정 파일에서 가져옵니다.\n","    # config['inference']['ckt_path']: 학습된 모델의 체크포인트 경로를 설정 파일에서 가져옵니다. 이 경로는 학습이 완료된 후 저장된 모델의 위치를 나타냅니다.\n","    model_name = config['general']['model_name']\n","    ckt_path = config['inference']['ckt_path']  # 학습된 모델의 체크포인트 경로\n","    ckt_path = \"/home/code/checkpoint-\" + checkpoint_num\n","    print(model_name, \" / \", ckt_path)\n","    print('-' * 10, f'Model Name : {model_name}', '-' * 10,)\n","\n","\n","    ### 토크나이저 로드 및 특수 토큰 추가:\n","    # AutoTokenizer.from_pretrained(model_name): 사전 학습된 모델 이름을 사용하여 토크나이저를 로드합니다.\n","    # tokenizer.add_special_tokens(special_tokens_dict): 설정 파일에서 정의된 특수 토큰을 토크나이저에 추가합니다. 이는 모델이 특정 단어들을 특수 토큰으로 처리할 수 있도록 합니다.\n","    print(\"\\n######  지정된 모델 이름으로부터 토크나이저를 로드합니다.\")\n","    # 지정된 모델 이름으로부터 토크나이저를 로드합니다.\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    print(\"\\n######  설정 파일에서 정의된 특수 토큰을 토크나이저에 추가합니다.\")\n","    # 설정 파일에서 정의된 특수 토큰을 토크나이저에 추가합니다.\n","    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n","    tokenizer.add_special_tokens(special_tokens_dict)\n","\n","\n","    ### 모델 로드:\n","    # BartForConditionalGeneration.from_pretrained(ckt_path): 학습된 모델의 체크포인트에서 BART 모델을 로드합니다.\n","    # generate_model.resize_token_embeddings(len(tokenizer)): 토크나이저에 추가된 특수 토큰에 맞춰 모델의 토큰 임베딩 크기를 재조정합니다.\n","    print(\"\\n######  학습된 체크포인트에서 BART 모델을 로드합니다.\")\n","    # 학습된 체크포인트에서 BART 모델을 로드합니다.\n","    generate_model = BartForConditionalGeneration.from_pretrained(ckt_path)\n","    print(\"\\n######  추가된 토큰에 맞게 모델의 토큰 임베딩 크기를 조정합니다.\")\n","    # 추가된 토큰에 맞게 모델의 토큰 임베딩 크기를 조정합니다.\n","    generate_model.resize_token_embeddings(len(tokenizer))\n","\n","\n","    ### 디바이스로 모델 이동:\n","    # generate_model.to(device): 로드된 모델을 지정된 디바이스(GPU 또는 CPU)로 이동시켜,\n","    # 추론 작업을 해당 디바이스에서 수행할 수 있도록 합니다.\n","    print(\"\\n######  모델을 지정된 디바이스(GPU 또는 CPU)로 이동시킵니다.\")\n","    # 모델을 지정된 디바이스(GPU 또는 CPU)로 이동시킵니다.\n","    generate_model.to(device)\n","\n","    print('-' * 10, 'Load tokenizer & model complete', '-' * 10,)\n","\n","\n","    ### 모델과 토크나이저 반환:\n","    # 최종적으로 불러온 모델과 토크나이저를 반환하여, 이후 추론 작업에서 사용할 수 있도록 합니다.\n","    return generate_model, tokenizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7Kcf1W8uU7E"},"outputs":[],"source":["print(\"\\n#######  추론을 위한 모델과 토크나이저를 불러옵니다.  ##############################################################################\")\n","# 추론을 위한 모델과 토크나이저를 불러옵니다.\n","generate_model, tokenizer = load_tokenizer_and_model_for_test(config, device)"]},{"cell_type":"markdown","metadata":{"id":"PbYBahXLuU7E"},"source":["### 2) 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0EInGukuU7E"},"outputs":[],"source":["print(\"\\n#######  데이터 경로와 전처리기를 설정합니다.  ####################################################################################\")\n","# 데이터 경로와 전처리기를 설정합니다.\n","data_path = config['general']['data_path']\n","preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])"]},{"cell_type":"markdown","metadata":{"id":"U5YoQOUFuU7E"},"source":["### 3) 테스트 데이터셋 준비"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBlOm8g0uU7E"},"outputs":[],"source":["# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n","def prepare_test_dataset(config, preprocessor, tokenizer):\n","\n","    ### 테스트 데이터 로드:\n","    # test_file_path에서 test.csv 파일을 읽어옵니다.\n","    test_file_path = os.path.join(config['general']['data_path'], 'test.csv')\n","    # Preprocess 클래스의 make_set_as_df 메서드를 사용하여 테스트 데이터를 데이터프레임으로 변환합니다. 이때, is_train=False로 설정하여 학습과 달리 요약(summary)이 포함되지 않은 테스트 데이터를 처리합니다.\n","    # test_data['fname']는 테스트 데이터의 고유 ID로, 각 샘플을 식별하는 데 사용됩니다.\n","    # 테스트 데이터를 데이터프레임으로 변환합니다. is_train=False로 설정하여 테스트 데이터셋을 로드합니다.\n","    test_data = preprocessor.make_set_as_df(test_file_path, is_train=False)\n","    test_id = test_data['fname']  # 테스트 데이터의 고유 ID (fname)을 가져옵니다.\n","\n","\n","    # 데이터 확인:\n","    # 테스트 데이터의 첫 번째 대화(dialogue) 샘플을 출력하여, 데이터가 올바르게 로드되었는지 확인합니다.\n","    print('-' * 150)\n","    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n","    print('-' * 150)\n","\n","\n","    ### 인코더 및 디코더 입력 생성:\n","    # Preprocess 클래스의 make_input 메서드를 사용하여 인코더 입력과 디코더 입력을 생성합니다.\n","    # 테스트 데이터의 경우, 디코더 입력은 시작 토큰(bos_token)만 포함합니다.\n","    # 테스트 데이터에 대해 인코더 입력과 디코더 입력을 생성합니다. is_test=True로 설정하여 디코더 입력에만 시작 토큰을 넣습니다.\n","    encoder_input_test, decoder_input_test = preprocessor.make_input(test_data, is_test=True)\n","    print('-' * 10, 'Load data complete', '-' * 10,)\n","\n","\n","    ### 토큰화:\n","    # tokenizer를 사용하여 인코더 입력과 디코더 입력을 토큰화합니다.\n","    # 이 과정에서 패딩, 특수 토큰 추가, 최대 길이 제한 등을 설정하여 텐서 형태로 반환합니다.\n","    # 테스트 데이터의 인코더 입력을 토크나이저로 토큰화합니다.\n","    test_tokenized_encoder_inputs = tokenizer(\n","        encoder_input_test, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,\n","    )\n","    # 테스트 데이터의 디코더 입력을 토크나이저로 토큰화합니다.\n","    test_tokenized_decoder_inputs = tokenizer(\n","        decoder_input_test, return_tensors=\"pt\", padding=True,\n","        add_special_tokens=True, truncation=True,\n","        max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,\n","    )\n","\n","\n","    ### 테스트 데이터셋 준비:\n","    # DatasetForInference 클래스를 사용하여 토큰화된 입력 데이터와 테스트 ID를 포함한 데이터셋 객체를 생성합니다.\n","    # 이 데이터셋 객체는 모델이 예측을 수행하는 데 사용됩니다.\n","    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n","    print('-' * 10, 'Make dataset complete', '-' * 10,)\n","\n","\n","    ### 결과 반환:\n","    # 원본 테스트 데이터(test_data)와 모델에 입력될 토큰화된 데이터셋(test_encoder_inputs_dataset)을 반환합니다.\n","    return test_data, test_encoder_inputs_dataset\n","\n","\n","    # 이 함수는 테스트 데이터를 전처리하여 모델에 적합한 입력 데이터로 준비합니다.\n","    # 이를 통해 학습된 모델이 테스트 데이터에 대한 예측을 정확하게 수행할 수 있도록 합니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ne6EZM_UuU7F"},"outputs":[],"source":["print(\"\\n#######  테스트 데이터셋을 준비합니다.  ##########################################################################################\")\n","# 테스트 데이터셋을 준비합니다.\n","test_data, test_encoder_inputs_dataset = prepare_test_dataset(config, preprocessor, tokenizer)\n"]},{"cell_type":"markdown","metadata":{"id":"N003ia6SuU7F"},"source":["### 4) 데이터 로더 생성 / 테스트 데이터 추론"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrLKvTZJuU7F"},"outputs":[],"source":["print(\"\\n#######  데이터 로더를 생성합니다. 배치 크기는 설정 파일에서 가져옵니다.  ##########################################################\")\n","# 데이터 로더를 생성합니다. 배치 크기는 설정 파일에서 가져옵니다.\n","dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n","\n","summary = []  # 요약문을 저장할 리스트\n","text_ids = []  # 텍스트 ID를 저장할 리스트\n","\n","with torch.no_grad():  # 추론 중에는 기울기 계산을 비활성화하여 메모리를 절약합니다.\n","    for item in tqdm(dataloader):  # 데이터 로더를 통해 배치 단위로 데이터에 접근합니다.\n","        text_ids.extend(item['ID'])  # 현재 배치의 텍스트 ID를 저장합니다.\n","        generated_ids = generate_model.generate(\n","            input_ids=item['input_ids'].to(device),  # 인코더 입력을 디바이스로 이동시켜 모델에 전달합니다.\n","            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],  # 반복 n-gram 방지 설정\n","            early_stopping=config['inference']['early_stopping'],  # 조기 종료 설정\n","            max_length=config['inference']['generate_max_length'],  # 생성할 텍스트의 최대 길이\n","            num_beams=config['inference']['num_beams'],  # 빔 서치(beam search)의 빔 수 설정\n","        )\n","        for ids in generated_ids:  # 생성된 요약문 ID를 디코딩하여 텍스트로 변환합니다.\n","            result = tokenizer.decode(ids, skip_special_tokens=False)  # 특수 토큰을 건너뛰고 디코딩합니다.\n","            summary.append(result)  # 생성된 요약문을 리스트에 추가합니다."]},{"cell_type":"markdown","metadata":{"id":"lxgQ7icRuU7F"},"source":["### 5) 최종 결과/요약문 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MHDCtvuwuU7F"},"outputs":[],"source":["print(\"\\n#######  스페셜 토큰을 제거하여 최종 요약문을 전처리합니다.  ######################################################################\")\n","# 스페셜 토큰을 제거하여 최종 요약문을 전처리합니다.\n","remove_tokens = config['inference']['remove_tokens']\n","preprocessed_summary = summary.copy()\n","for token in remove_tokens:\n","    preprocessed_summary = [sentence.replace(token, \" \") for sentence in preprocessed_summary]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtbMUqh2uU7F"},"outputs":[],"source":["\n","for i in range(len(preprocessed_summary)):\n","    tmp = preprocessed_summary[i]\n","    left_trimmed = tmp.lstrip()  # 왼쪽 공백 제거\n","    right_trimmed = left_trimmed.rstrip()  # 오른쪽 공백 제거\n","    tmp = right_trimmed\n","    tmp = tmp.replace('# ', '#')\n","    preprocessed_summary[i] = tmp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJZa3zFLuU7G"},"outputs":[],"source":["preprocessed_summary"]},{"cell_type":"markdown","metadata":{"id":"JfLH5VjSuU7G"},"source":["### 6) 최종 결과 데이터프레임으로 정리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLSNp03LuU7G"},"outputs":[],"source":["print(\"\\n#######  최종 결과를 데이터프레임으로 정리합니다. ###############################################################################\")\n","# 최종 결과를 데이터프레임으로 정리합니다.\n","output = pd.DataFrame({\n","    \"fname\": test_data['fname'],  # 파일 이름\n","    \"summary\": preprocessed_summary,  # 전처리된 요약문\n","})"]},{"cell_type":"markdown","metadata":{"id":"X6o9oX9vuU7G"},"source":["### 7) CSV 파일 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IyTO0icuU7G"},"outputs":[],"source":["print(\"#######  \", model.replace(\"/\", \"-\") + para + \"-ck\" + checkpoint_num + \"_output.csv\" + \"  파일명이 완성되었습니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQN_8HkvuU7G"},"outputs":[],"source":["print(\"\\n#######  결과를 저장할 경로를 설정하고, 결과를 CSV 파일로 저장합니다.  ##########################################################\")\n","# 결과를 저장할 경로를 설정하고, 결과를 CSV 파일로 저장합니다.\n","result_path = config['inference']['result_path']\n","if not os.path.exists(result_path):\n","    os.makedirs(result_path)  # 경로가 존재하지 않으면 디렉토리를 생성합니다.\n","output.to_csv(os.path.join(result_path, model.replace(\"/\", \"-\") + para + \"-ck\" + checkpoint_num + \"_output.csv\"), index=False)  # 결과를 CSV 파일로 저장합니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PM0SmPc5uU7G"},"outputs":[],"source":["# 결과 확인\n","output"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dad34778350e46358944311abb26b4bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7739a59001124e83ac2b38b6ea33ba11","IPY_MODEL_2dba2726a7bd49c7a4bf200766e5baac","IPY_MODEL_b37c223b354240a09306ab66fddd9fb1"],"layout":"IPY_MODEL_5a5b335716824d3ba444e4bfd06070c9"}},"7739a59001124e83ac2b38b6ea33ba11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e345f2e8c8cb4cfe8eb9f1ae7d2d4330","placeholder":"​","style":"IPY_MODEL_9604fbfe6c0e490fb671224fec6b3ca2","value":"tokenizer_config.json: 100%"}},"2dba2726a7bd49c7a4bf200766e5baac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05554a3c1a704e45a965ca804c560da4","max":472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd633cebc980491a89152679a9c7b002","value":472}},"b37c223b354240a09306ab66fddd9fb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c1725c06a1c493d8d62f654743a2029","placeholder":"​","style":"IPY_MODEL_7ea9b168115349eb837b66fb89bc7b2e","value":" 472/472 [00:00&lt;00:00, 7.77kB/s]"}},"5a5b335716824d3ba444e4bfd06070c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e345f2e8c8cb4cfe8eb9f1ae7d2d4330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9604fbfe6c0e490fb671224fec6b3ca2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05554a3c1a704e45a965ca804c560da4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd633cebc980491a89152679a9c7b002":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c1725c06a1c493d8d62f654743a2029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea9b168115349eb837b66fb89bc7b2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"470533f69d8f4b419ee7fc77ce43194c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf36213116274c0da78089e1e4b8d556","IPY_MODEL_6a14b1ee34134ba9992f5d10c8f3102f","IPY_MODEL_f216aca8a26c4e1b9ee57b2cda2813f2"],"layout":"IPY_MODEL_45d6b73bbaa440bf91b3094f205e4ac5"}},"bf36213116274c0da78089e1e4b8d556":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5999d2518ba44aa9b63743af7b6f350","placeholder":"​","style":"IPY_MODEL_67908eee87564e7090a4b124620419c2","value":"tokenizer.json: 100%"}},"6a14b1ee34134ba9992f5d10c8f3102f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57dde2cfebbf444c88d522d8eedc1419","max":1055396,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3da24c9e9f0a454c8239e932cbfb5df2","value":1055396}},"f216aca8a26c4e1b9ee57b2cda2813f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44953bbb5e744d1ab2d322e393eccf89","placeholder":"​","style":"IPY_MODEL_9bef013ac5f347aa88302f2b3da23320","value":" 1.06M/1.06M [00:00&lt;00:00, 2.41MB/s]"}},"45d6b73bbaa440bf91b3094f205e4ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5999d2518ba44aa9b63743af7b6f350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67908eee87564e7090a4b124620419c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57dde2cfebbf444c88d522d8eedc1419":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da24c9e9f0a454c8239e932cbfb5df2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44953bbb5e744d1ab2d322e393eccf89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bef013ac5f347aa88302f2b3da23320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77db6d046b424c8cb1c880804a7266a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03a29e19e55a4709a482174fa5f2f3f4","IPY_MODEL_822917dd324247c99cfc5ad0204f991a","IPY_MODEL_f8828b027337456ca79440a26ee468eb"],"layout":"IPY_MODEL_3805724fb39a4d4e906c4ffed8af26c2"}},"03a29e19e55a4709a482174fa5f2f3f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c153a5cd8be452d9f41eaced17c165f","placeholder":"​","style":"IPY_MODEL_4476b7cd6aff49f0a652f66de7ce3b4e","value":"special_tokens_map.json: 100%"}},"822917dd324247c99cfc5ad0204f991a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc536aaa2d9a4bd8adef874bac22bcd8","max":843,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a97d407462342948ba03410897027dc","value":843}},"f8828b027337456ca79440a26ee468eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68b7a67166024621b3393cef5cb96193","placeholder":"​","style":"IPY_MODEL_eccb54365c3e4af0a35ac6e4ebc389bf","value":" 843/843 [00:00&lt;00:00, 21.3kB/s]"}},"3805724fb39a4d4e906c4ffed8af26c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c153a5cd8be452d9f41eaced17c165f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4476b7cd6aff49f0a652f66de7ce3b4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc536aaa2d9a4bd8adef874bac22bcd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a97d407462342948ba03410897027dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68b7a67166024621b3393cef5cb96193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eccb54365c3e4af0a35ac6e4ebc389bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0cb595dc9ac4896b85ada713ddf49f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdfe08aec75949fb95d4cebe10b1ec17","IPY_MODEL_a7be9039bcfe497c97888d5bfdfd231a","IPY_MODEL_9eb6d93455b440e99bb1ff07f76e1c3d"],"layout":"IPY_MODEL_8ceb9e746e0341ae81f7a11a96401566"}},"fdfe08aec75949fb95d4cebe10b1ec17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec7f93ca4ea9453892cb5a6c9699433c","placeholder":"​","style":"IPY_MODEL_df0cb538f20d46c7be0f38ae49bcdf96","value":"config.json: 100%"}},"a7be9039bcfe497c97888d5bfdfd231a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_464f872db2a54d6081f504183735a922","max":1819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e717bb64d5134494a2cd93c9a563a51c","value":1819}},"9eb6d93455b440e99bb1ff07f76e1c3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13639687c93b4c8393f48b2f942818f3","placeholder":"​","style":"IPY_MODEL_ece27f48627b4fb4aa9b79a1271d632d","value":" 1.82k/1.82k [00:00&lt;00:00, 78.8kB/s]"}},"8ceb9e746e0341ae81f7a11a96401566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec7f93ca4ea9453892cb5a6c9699433c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df0cb538f20d46c7be0f38ae49bcdf96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"464f872db2a54d6081f504183735a922":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e717bb64d5134494a2cd93c9a563a51c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13639687c93b4c8393f48b2f942818f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece27f48627b4fb4aa9b79a1271d632d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4d4c97959a94325af0c23e68ce9618b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d21add2963948b085f3dc949d169f2e","IPY_MODEL_30b4b353d77b42b78c270f86c4788231","IPY_MODEL_0d8108a9a901427fa833374190694bb0"],"layout":"IPY_MODEL_92886a84d19741f0941dbc4dc8a68fb4"}},"9d21add2963948b085f3dc949d169f2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e78cd0aa3f249e6b98f6186bee68e4f","placeholder":"​","style":"IPY_MODEL_5a3c3382e4d5436796af47505ddada9b","value":"pytorch_model.bin: 100%"}},"30b4b353d77b42b78c270f86c4788231":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd5cd53d9a094b408c27c343bc4ac8e8","max":495743133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e216987afb24a1aa40dd7b28141763f","value":495743133}},"0d8108a9a901427fa833374190694bb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b5cae3283042a6babf46045195e5ed","placeholder":"​","style":"IPY_MODEL_54a7636c0ac445019752e4cf3f2c4a19","value":" 496M/496M [00:04&lt;00:00, 116MB/s]"}},"92886a84d19741f0941dbc4dc8a68fb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e78cd0aa3f249e6b98f6186bee68e4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a3c3382e4d5436796af47505ddada9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd5cd53d9a094b408c27c343bc4ac8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e216987afb24a1aa40dd7b28141763f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9b5cae3283042a6babf46045195e5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a7636c0ac445019752e4cf3f2c4a19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}